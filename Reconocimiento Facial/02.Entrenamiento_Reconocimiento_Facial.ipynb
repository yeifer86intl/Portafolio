{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "dataPath = 'C:/Users/yeife/OneDrive/Escritorio/Reconocimiento Facial/data' #Cambia a la ruta donde hayas almacenado Data\n",
    "#Listamos las carpetas que estan donde almacenamos las capturas de las fotos, en este caso, solo esta la carpeta: Yeifer.\n",
    "peopleList = os.listdir(dataPath)\n",
    "print('Lista de personas con Captures: ', peopleList)\n",
    "\n",
    "#Estos arrays serviran para vincular a una persona (facesData) con una etiqueta(labels), en este caso: Yeifer está vinculado\n",
    "# a 0, porque hay una sola carpeta (Yeifer=0).\n",
    "\n",
    "labels = []\n",
    "facesData = []\n",
    "label = 0\n",
    "\n",
    "#Lectura de las carpetas dentro de la carpeta asignada a dataPath.\n",
    "for nameDir in peopleList:\n",
    "    personPath = dataPath + '/' + nameDir\n",
    "    print('Leyendo las imágenes de:')\n",
    "\n",
    "    #Lectura de los captures dentro de cada carpeta carpeta en datapath.\n",
    "    for fileName in os.listdir(personPath):\n",
    "        print('Rostros de: ', nameDir + '/' + fileName)\n",
    "        labels.append(label)\n",
    "        facesData.append(cv2.imread(personPath+'/'+fileName,0))\n",
    "        #Imprime las fotos tomadas\n",
    "        image = cv2.imread(personPath+'/'+fileName,0)\n",
    "        cv2.imshow('image',image)\n",
    "        cv2.waitKey(10)\n",
    "    #contador que asigna el valor a label en cada iteración.\n",
    "    label = label + 1\n",
    "\n",
    "#Verifica cuantos captures hay en la carpeta: Yeifer.\n",
    "print('labels= ',labels)\n",
    "print('Número de etiquetas 0: ',np.count_nonzero(np.array(labels)==0))\n",
    "\n",
    "\n",
    "# Existen 3 métodos para entrenar el modelo.\n",
    "#face_recognizer = cv2.face.EigenFaceRecognizer_create()\n",
    "#face_recognizer = cv2.face.FisherFaceRecognizer_create()\n",
    "face_recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "# Aviso cuando el modelo está entrenando.\n",
    "print(\" ENTRENANDO\")\n",
    "face_recognizer.train(facesData, np.array(labels))\n",
    "\n",
    "# Almacenando el modelo obtenido\n",
    "#face_recognizer.write('modeloEigenFace.xml')\n",
    "#face_recognizer.write('modeloFisherFace.xml')\n",
    "face_recognizer.write('modeloLBPHFace.xml')\n",
    "print(\"MODELO GUARDADO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para cerrar la pantalla de los captures solo hay que cerrar jupyter o en su defecto tomar\n",
    "# la opcion: Restart and clear output en kernel."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
