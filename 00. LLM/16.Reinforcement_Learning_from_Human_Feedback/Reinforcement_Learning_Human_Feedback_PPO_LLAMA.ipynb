{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cb7b12c"
      },
      "source": [
        "# Reinforcement Learning from Human Feedback con PPO sobre TinyLLAMA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42e9ea52"
      },
      "source": [
        "<div style=\"background-color:#D9EEFF;color:black;padding:2%;\">\n",
        "<h2>Enunciado del caso práctico</h2>\n",
        "\n",
        "En este caso práctico, se propone al alumno la realización de Reinforcement Learning from Human Feedback para evitar la generación de contenido tóxico sobre una versión reducida de LLAMA denominada [TinyLLAMA](https://huggingface.co/PY007/TinyLlama-1.1B-Chat-v0.3)\n",
        "\n",
        "Por oto lado, como algoritmo de recompensa (Reward model) se propone el uso de una versión de [RoBERTa](https://huggingface.co/docs/transformers/model_doc/roberta) con fine-tuning para la detección de comportamiento tóxico/hate: https://huggingface.co/facebook/roberta-hate-speech-dynabench-r4-target\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "831d29b1"
      },
      "source": [
        "# Resolución del caso práctico"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-V8dgd_BUeOK"
      },
      "source": [
        "## 0. Instalación de librerías externas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "iNYL3gnJXsEa",
        "outputId": "b878b604-2932-4d4c-ee06-934a5c533ddf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q accelerate peft==0.7.0 bitsandbytes transformers trl xformers trl evaluate sentencepiece"
      ],
      "metadata": {
        "id": "vPIR50tPH6rf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjNFCLMHWCXs"
      },
      "source": [
        "## 1. Lectura del modelo y del tokenizador"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1. Descarga del modelo y del tokenizador"
      ],
      "metadata": {
        "id": "KalsBY6woqmG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para reducir el consumo de recursos copmutacionales, sobre todo memoria RAM, durante el proceso de re-entrenamiento y Reinforcement Learning vamos a aplir QLoRA sobre el modelo."
      ],
      "metadata": {
        "id": "SnFaFP9goGzb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WdK3d284lxFw"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "# Definimos los paramétros para bitsandbytes\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sNfU5_BKOTp1",
        "outputId": "43f8d920-5250-42fb-fd0c-0669dbeb9902",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Nombre del modelo\n",
        "model_name = \"PY007/TinyLlama-1.1B-Chat-v0.3\"\n",
        "\n",
        "# Leemos el modelo pre-entrenado el modelo LLAMA2-7b-chat\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map={\"\": 0},\n",
        "    low_cpu_mem_usage=True # Reduccion del consumo de cpu y memoria al leer el modelo\n",
        ")\n",
        "\n",
        "CHAT_EOS_TOKEN_ID = 32002"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vAl7HAdNPjDT",
        "outputId": "557b2c4a-19be-47c8-ad1b-a42f39327994",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Leemos el tokenizador\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "652jxcqawjQk"
      },
      "source": [
        "### 1.2. Generación de texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9ErX-b24n4Ll"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Creamos un pipeline para la tokenización y generación del texto\n",
        "tinyllama_pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        "    do_sample=True,\n",
        "    top_k=50,\n",
        "    top_p=0.9,\n",
        "    num_return_sequences=1,\n",
        "    repetition_penalty=1.1,\n",
        "    max_new_tokens=200,\n",
        "    eos_token_id=CHAT_EOS_TOKEN_ID,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9DCvtETXWJJT"
      },
      "outputs": [],
      "source": [
        "prompt = \"Actúa como si fueses el mayor experto en historia del mundo. Describe \\\n",
        "en pocas palabras lo que ocurrió en la segunda guerra mundial.\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = f\"<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n\"\n",
        "\n",
        "print(prompt_template)"
      ],
      "metadata": {
        "id": "U0gJLc0DJo79",
        "outputId": "e06b9bb7-7597-45db-9046-f4ee432571eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|im_start|>user\n",
            "Actúa como si fueses el mayor experto en historia del mundo. Describe en pocas palabras lo que ocurrió en la segunda guerra mundial.<|im_end|>\n",
            "<|im_start|>assistant\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pelMVjGATwUO",
        "outputId": "01a79b27-3cba-4a29-f691-ae17f76bbda6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|im_start|>user\n",
            "Actúa como si fueses el mayor experto en historia del mundo. Describe en pocas palabras lo que ocurrió en la segunda guerra mundial.<|im_end|>\n",
            "<|im_start|>assistant\n",
            "En la segunda guerra mundial, los alemanes invadieron a Italia y Francia en 1939. Se estima que más de un millón personas murieron o se exiliaron en torno a la frontera fría con Polonia. El ataque al frente alemán fue liderado por el general Adolf Hitler, quien pretendía establecer una Alemania oriental y racional, mientras que el objetivo polaco era destruir la línea de defensa aliada que protegía Warsaw y la ciudad de Stalingrado. La lucha por lograr una alianza frontal contra ambos enemigos fue sangrienta. El mes de mayo de 1940 fue el pico de esta lucha y el frente tren-artillería de la primera campana de combates se cruzó el día 8 de mayo de ese mes, con una línea de acción de unos 70 kilómetros\n"
          ]
        }
      ],
      "source": [
        "# Invocamos el pipeline para realizar generación de texto\n",
        "output = tinyllama_pipe(prompt_template)\n",
        "print(output[0]['generated_text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01t6CnUB_Lns"
      },
      "source": [
        "## 2. Selección y preparación del conjunto de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para este caso práctico vamos a utilizar un conjunto de datos denominado [Dialogsum](https://huggingface.co/datasets/knkarthick/dialogsum):\n",
        "\n",
        "DialogSum es un conjunto de datos de resumen de diálogos a gran escala, compuesto por 13.460 diálogos divididos en entrenamiento, prueba y validación.\n",
        "\n",
        "Ejemplo del conjunto de datos:\n",
        "\n",
        "```\n",
        "{'id': 'train_0', 'summary': \"Mr. Smith's getting a check-up, and Doctor Hawkins advises him to have one every year. Hawkins'll give some information about their classes and medications to help Mr. Smith quit smoking.\", 'dialogue': \"#Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. Why are you here today?\\n#Person2#: I found it would be a good idea to get a check-up.\\n#Person1#: Yes, well, you haven't had one for 5 years. You should have one every year.\\n#Person2#: I know. I figure as long as there is nothing wrong, why go see the doctor?\\n#Person1#: Well, the best way to avoid serious illnesses is to find out about them early. So try to come at least once a year for your own good.\\n#Person2#: Ok.\\n#Person1#: Let me see here. Your eyes and ears look fine. Take a deep breath, please. Do you smoke, Mr. Smith?\\n#Person2#: Yes.\\n#Person1#: Smoking is the leading cause of lung cancer and heart disease, you know. You really should quit.\\n#Person2#: I've tried hundreds of times, but I just can't seem to kick the habit.\\n#Person1#: Well, we have classes and some medications that might help. I'll give you more information before you leave.\\n#Person2#: Ok, thanks doctor.\", 'topic': \"get a check-up}\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "fJqqeQ3gv-aa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBM_wgklBoJE"
      },
      "source": [
        "### 2.1. Lectura del conjunto de datos"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"knkarthick/dialogsum\")"
      ],
      "metadata": {
        "id": "Y44NC6D8sz2g"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds"
      ],
      "metadata": {
        "id": "TWAT_fRtxUcw",
        "outputId": "8854b279-b33c-4685-ee8f-b8388c5d6b99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
              "        num_rows: 12460\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
              "        num_rows: 500\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
              "        num_rows: 1500\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reducimos el conjunto de datos\n",
        "NUM_EJ_TRAIN = 1000\n",
        "NUM_EJ_VAL = 100\n",
        "NUM_EJ_TEST = 100\n",
        "\n",
        "# Subconjunto de entrenamiento\n",
        "ds['train'] = ds['train'].select(range(NUM_EJ_TRAIN))\n",
        "\n",
        "# Subconjunto de validación\n",
        "ds['validation'] = ds['validation'].select(range(NUM_EJ_VAL))\n",
        "\n",
        "# Subconjunto de pruebas\n",
        "ds['test'] = ds['test'].select(range(NUM_EJ_TEST))"
      ],
      "metadata": {
        "id": "2uKsPh3o8zJq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ds['train']['dialogue'][2])"
      ],
      "metadata": {
        "id": "9Afvjeve9A8c",
        "outputId": "2dc91133-4e4d-472a-df1f-0d5983e1cc94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Person1#: Excuse me, did you see a set of keys?\n",
            "#Person2#: What kind of keys?\n",
            "#Person1#: Five keys and a small foot ornament.\n",
            "#Person2#: What a shame! I didn't see them.\n",
            "#Person1#: Well, can you help me look for it? That's my first time here.\n",
            "#Person2#: Sure. It's my pleasure. I'd like to help you look for the missing keys.\n",
            "#Person1#: It's very kind of you.\n",
            "#Person2#: It's not a big deal.Hey, I found them.\n",
            "#Person1#: Oh, thank God! I don't know how to thank you, guys.\n",
            "#Person2#: You're welcome.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2. Preparación del conjunto de datos para proporcionarlo al algoritmo"
      ],
      "metadata": {
        "id": "I_XW2E-KCp87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prep_dataset(dataset, tokenizer, input_min_text_length, input_max_text_length):\n",
        "\n",
        "    # Filtramos los dialogos que se encuentran entre el tamaño minimo y maximo\n",
        "    dataset[\"train\"] = dataset[\"train\"].filter(lambda x: len(x[\"dialogue\"]) > input_min_text_length and len(x[\"dialogue\"]) <= input_max_text_length, batched=False)\n",
        "    dataset[\"validation\"] = dataset[\"validation\"].filter(lambda x: len(x[\"dialogue\"]) > input_min_text_length and len(x[\"dialogue\"]) <= input_max_text_length, batched=False)\n",
        "    dataset[\"test\"] = dataset[\"test\"].filter(lambda x: len(x[\"dialogue\"]) > input_min_text_length and len(x[\"dialogue\"]) <= input_max_text_length, batched=False)\n",
        "\n",
        "    def tokenize(sample):\n",
        "        # Plantilla de entrenamiento para cada ejemplo\n",
        "        prompt = f\"\"\"\n",
        "Summarize the following conversation.\n",
        "\n",
        "{sample[\"dialogue\"]}\n",
        "\n",
        "Summary:\n",
        "\"\"\"\n",
        "        sample[\"input_ids\"] = tokenizer.encode(prompt)\n",
        "        # Esto debe llamarse \"query\", es un requisito de la biblioteca PPO\n",
        "        sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n",
        "        return sample\n",
        "\n",
        "    # Tokenizamos cada dialogo\n",
        "    dataset = dataset.map(tokenize, batched=False)\n",
        "\n",
        "    # Convertimos el conjunto de datos a un formato adecuado\n",
        "    dataset.set_format(type=\"torch\")\n",
        "\n",
        "    return dataset\n"
      ],
      "metadata": {
        "id": "KYGeGTaCtCbw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = prep_dataset(ds, tokenizer, input_min_text_length=200, input_max_text_length=1024)"
      ],
      "metadata": {
        "id": "k-Sg2zOgy95t"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ds[\"train\"][\"query\"][0])"
      ],
      "metadata": {
        "id": "uiEhhyf-tO-Z",
        "outputId": "6d8f389c-2a6a-4949-e5c3-1542e32d8d5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "Summarize the following conversation.\n",
            "\n",
            "#Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. Why are you here today?\n",
            "#Person2#: I found it would be a good idea to get a check-up.\n",
            "#Person1#: Yes, well, you haven't had one for 5 years. You should have one every year.\n",
            "#Person2#: I know. I figure as long as there is nothing wrong, why go see the doctor?\n",
            "#Person1#: Well, the best way to avoid serious illnesses is to find out about them early. So try to come at least once a year for your own good.\n",
            "#Person2#: Ok.\n",
            "#Person1#: Let me see here. Your eyes and ears look fine. Take a deep breath, please. Do you smoke, Mr. Smith?\n",
            "#Person2#: Yes.\n",
            "#Person1#: Smoking is the leading cause of lung cancer and heart disease, you know. You really should quit.\n",
            "#Person2#: I've tried hundreds of times, but I just can't seem to kick the habit.\n",
            "#Person1#: Well, we have classes and some medications that might help. I'll give you more information before you leave.\n",
            "#Person2#: Ok, thanks doctor.\n",
            "\n",
            "Summary:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFVyogGn0ruV"
      },
      "source": [
        "## 3. Configuración Reinforcement Learning from Human Feedback"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKOiXMJBMBPD"
      },
      "source": [
        "### 3.1. Configuración de LoRA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnDnMYV-HYtW"
      },
      "source": [
        "La siguiente función es interesante para comparar el número de parámetros entrenables que tiene el modelo antes y después de apalicar LoRA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "hWyRL5IhUpu3"
      },
      "outputs": [],
      "source": [
        "def print_trainable_parameters(model):\n",
        "    trainable_model_params = 0\n",
        "    all_model_params = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_model_params += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_model_params += param.numel()\n",
        "    return f\"\\ntrainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "OZ7xJDTFUqtF",
        "outputId": "77ef7e07-4308-4a7c-8d7d-70277661dc28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "trainable model parameters: 131176448\n",
            "all model parameters: 615618560\n",
            "percentage of trainable model parameters: 21.31%\n"
          ]
        }
      ],
      "source": [
        "print(print_trainable_parameters(model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxiTkz4zy8aK"
      },
      "source": [
        "Configuramos LoRA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "a-il4eI-L4yg"
      },
      "outputs": [],
      "source": [
        "from peft import LoraConfig, get_peft_model, prepare_model_for_int8_training\n",
        "\n",
        "# Definición de la configuración de LoRA\n",
        "lora_config = LoraConfig(\n",
        "                 r = 16, # Dimensión de las matrices\n",
        "                 lora_alpha = 16, # LoRA scaling factor\n",
        "                 lora_dropout = 0.05, # Regularización\n",
        "                 bias=\"none\",\n",
        "                 task_type=\"CAUSAL_LM\" # Tipo de tarea/modelo al que aplicarlo\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "UtqgSmk7zB5U",
        "outputId": "96fec396-1063-4498-a193-0b20b97fbaa1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 2,252,800 || all params: 1,102,313,472 || trainable%: 0.20437017756052608\n"
          ]
        }
      ],
      "source": [
        "# Aplicamos la configuración al modelo\n",
        "model_peft = get_peft_model(model, lora_config)\n",
        "\n",
        "# Mostramos el número de parámetros que se van a entrenar\n",
        "model_peft.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXTs5vb_RTQp"
      },
      "source": [
        "### 3.2. Configuración (Proximal Policy Optimization)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Durante el proceso de PPO, sólo se actualizarán algunos parámetros. En concreto, los parámetros entrenables con LoRA junto con algunos parámetros adicionales. Puedes encontrar más información sobre esta clase de modelos en [su documentación](https://huggingface.co/docs/trl/main/en/models#trl.create_reference_model).\n",
        "\n",
        "El número de parámetros entrenables puede calcularse como `(𝑛+1)∗𝑚`\n",
        " donde `𝑛` es el número de unidades de entrada (aquí `𝑛=2048`) y `𝑚` es el número de unidades de salida (aquí `𝑚=1`). El término `+1` en la ecuación tiene en cuenta el término bias.\n",
        "\n",
        "E nuestro caso, el número de parámetros entrenables debe ser: `2,252,800 + 2.049 = 2.254.849 parámetros`"
      ],
      "metadata": {
        "id": "05LCMPE9NAvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import AutoModelForCausalLMWithValueHead\n",
        "\n",
        "ppo_model = AutoModelForCausalLMWithValueHead.from_pretrained(model_peft,\n",
        "                                                              torch_dtype=torch.bfloat16,\n",
        "                                                              is_trainable=True,\n",
        "                                                              device_map={\"\": 0},\n",
        ")\n",
        "\n",
        "print(f'Parametros entrenables PPO Model:\\n{print_trainable_parameters(ppo_model)}\\n')\n",
        "print(ppo_model.v_head)"
      ],
      "metadata": {
        "id": "tHGIu3lpMkYA",
        "outputId": "fb24ed87-5821-4dd0-85f1-ae973e92ca3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parametros entrenables PPO Model:\n",
            "\n",
            "trainable model parameters: 2254849\n",
            "all model parameters: 617873409\n",
            "percentage of trainable model parameters: 0.36%\n",
            "\n",
            "ValueHead(\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (summary): Linear(in_features=2048, out_features=1, bias=True)\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tal y como hemos comentado en secciones anteriores, además del modelo que vamos a ir ajustando en el proceso de Reinforcement Learning, se requiere una instancia del mismo modelo con los parámetros congelados para que sirva de referencia y calcular las probabilidades relativas de los tokens generados.\n",
        "\n",
        "El modelo de referencia representará el LLM antes de la \"desintoxicación\". Ninguno de los parámetros del modelo de referencia se actualizará durante el entrenamiento utilizando PPO."
      ],
      "metadata": {
        "id": "R4UYubHiOHrW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import create_reference_model\n",
        "\n",
        "ref_model = create_reference_model(ppo_model)\n",
        "\n",
        "print(f'Parámetros entrenables modelo de referencia:\\n{print_trainable_parameters(ref_model)}\\n')"
      ],
      "metadata": {
        "id": "ecK3Db5JOISo",
        "outputId": "3592b691-1192-4ace-f00a-af7224c1fdfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parámetros entrenables modelo de referencia:\n",
            "\n",
            "trainable model parameters: 0\n",
            "all model parameters: 617873409\n",
            "percentage of trainable model parameters: 0.00%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3. Creación del Reward Model"
      ],
      "metadata": {
        "id": "BTKiMGenO5rx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo siguiente que debemos hacer es selccionar el modelo de reocmpensas (Reward model).\n",
        "\n",
        "Para este caso práctico vamos a hacer uso de una versión de [RoBERTa](https://huggingface.co/docs/transformers/model_doc/roberta) con fine-tuning que ha creado Meta (Facebook) para la detección de comportamiento tóxico/hate: https://huggingface.co/facebook/roberta-hate-speech-dynabench-r4-target\n",
        "\n",
        "El modelo predecirá las probabilidades de que un texto pertenezca a una de las dos clases: `(no_hate, hate)`"
      ],
      "metadata": {
        "id": "V6EUWaUwO-ed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "reward_model_name = \"facebook/roberta-hate-speech-dynabench-r4-target\"\n",
        "\n",
        "# Cargamos el modelo\n",
        "reward_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    reward_model_name, device_map=\"auto\")\n",
        "\n",
        "# Cargamos el tokenizador\n",
        "reward_tokenizer = AutoTokenizer.from_pretrained(\n",
        "    reward_model_name, device_map=\"auto\")\n",
        "\n",
        "# Etiquetas del modelo\n",
        "print(f\"\\nEtiquetas del modelo: {reward_model.config.id2label}\")"
      ],
      "metadata": {
        "id": "xOV5z98sPAvZ",
        "outputId": "7c957a8b-696b-4c05-9b0b-09e1a73a0a84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244,
          "referenced_widgets": [
            "16fce2120a204630bacf3429499f8541",
            "db3c7d09185b47f19fafce6c0896c8b9",
            "afd2a02b1d0d45f6ad6396efc04f83ee",
            "f43de88df44d439caf60051bebdbb078",
            "3da7811bfdc349b69bc52ad72f031f3d",
            "a170414476ca47ec85fbe006f8549fef",
            "7f4af298ce934f0d9e5f524b60e781a4",
            "7e4cb558e5674f8e82d2aa57a946b817",
            "a0540bfb790845af93e25dfdb2bfcb00",
            "4187256f4cf84f2a9333fb31ee9ca607",
            "e4980fc4ea6e4aae95603ea770582cdd",
            "aa1b3f31a9124adeb5155109200e636d",
            "4d796090d0784cb0a180f807b8aa7ddf",
            "8cafe4e97cec4eabbc4bd99cbc4a36c3",
            "b63392362e394421b4697c13d94165d1",
            "18a714115921420db350de9ee0ae97cd",
            "4813bbf369b14f6ba96e2d4f95141566",
            "393312a6f8a4438ca6e96dd257bc22dc",
            "8294f6016a204444a054fca85a685d6e",
            "641e098b365742c18f2fb69c81d6a54b",
            "0375fab107004d29bb2552714243f533",
            "539022cccc954649b197676898ff96e0",
            "e25d927a434d409f85ccb0abbf1f7a91",
            "e8c8ec85bab2423d9ef7751479668c72",
            "a572a87562ef46d1a26bbdbc7f75aad1",
            "c3568b3c03d74b0387fe9903898a8a8b",
            "006047f81d2f4480872a5210c1ae7f46",
            "e7d69ace2c134491ab1acd507f4be9ff",
            "f2b9859b1b9b42229b1c2578eebcc0ae",
            "acf3d2c7b5b14502b42de62a316213b1",
            "03bb6dc07caf40bab6d6ac5ad3373749",
            "ff3aae2eda2b4ba4a9ed65da16dfaf64",
            "df0fef4836cb4787a79e2026297c0a7c",
            "afe18827336b416ca269d60bd7a041b0",
            "f4f4594b1c904ac78dffb384bf05ae38",
            "ed4b7ff4893e4662bfccd7e04c426e24",
            "aa5d3454d1ba446d898a5d0f58f6dca2",
            "7c0129e68f334f579d49749074c4bb02",
            "3fa2a930bb5f4450b6589fe36c89f3a9",
            "39b8757053704796a8b54a6803e0f7aa",
            "bdb75176d80c44f696650e088acffbbd",
            "1113c50ff49c42be80ae567673dc58b6",
            "749b5ee64e23424595f3e8ba59fc2575",
            "b17b4dae53d749ee825aecfe4fe9fb82",
            "84b0f41aa1c24c889c72a96615227dd9",
            "2f55072dc6d64cd78e3a480a5f75d037",
            "3c81cf016eb8406fbb5540e1e3e53933",
            "72e63e8dca8c49189121bee9da23d380",
            "c5a5e9207839472f87fd6f790c982e01",
            "20c154e15ca844be817fa1e33a4a94b5",
            "a1b614c6bd3347bd99b346c5d24818dd",
            "55fbc2bb5d5e4ba091b1013c3b6290d2",
            "56f0be8a83cf49e08e80eba235371032",
            "828b0308481f440cb9b984d2cf102319",
            "e9bd7206942c48eb9cd149047407aa70",
            "8bba2a0a15034d798111a6542b160957",
            "110274e8369f4cf5850466e4ec640187",
            "18c988e467104ac3bf56fdb970708818",
            "f05d7ce66d1e42ea985a4ff2993955f0",
            "9aa3b61a94454d30963c937f16e4c036",
            "a8ab6057a6bd4963afc56351ce79eaee",
            "ea7894625e404e1c809c8a700f5a9c7e",
            "d3116e6a388647a28770c4f981b8c34d",
            "d52cff08eeb94233afc1425e30fdfcc3",
            "cc3cc0b79d2f4dcb837b8241c773aa00",
            "200419afc33c4090a154a3e77b9c6ea9"
          ]
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/816 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "16fce2120a204630bacf3429499f8541"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa1b3f31a9124adeb5155109200e636d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.11k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e25d927a434d409f85ccb0abbf1f7a91"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "afe18827336b416ca269d60bd7a041b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "84b0f41aa1c24c889c72a96615227dd9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8bba2a0a15034d798111a6542b160957"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Etiquetas del modelo: {0: 'nothate', 1: 'hate'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación se muestra como funcionaría el proceso de generación de la recompensa."
      ],
      "metadata": {
        "id": "KMmyhGgJ3O1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reward_evaluation(text):\n",
        "\n",
        "  toxicity_input_ids = reward_tokenizer(text, return_tensors=\"pt\").input_ids\n",
        "\n",
        "  logits = reward_model(input_ids=toxicity_input_ids.to('cuda')).logits\n",
        "  print(f'logits [not hate, hate]: {logits.tolist()[0]}')\n",
        "\n",
        "  # Mostramos las probabilidades para cada categoria: [not hate, hate]\n",
        "  probabilities = logits.softmax(dim=-1).tolist()[0]\n",
        "  print(f'probabilities [not hate, hate]: {probabilities}')\n",
        "\n",
        "  # Mostramos la recompensa\n",
        "  not_hate_index = 0\n",
        "  nothate_reward = (logits[:, not_hate_index]).tolist()\n",
        "  print(f'reward (high): {nothate_reward}')"
      ],
      "metadata": {
        "id": "SNwT1w5fPloG"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Persona 1# le dice a Juan que no ha visto la pelicula.\n",
        "non_toxic_text = \"#Person 1# tells Tommy that he didn't like the movie.\"\n",
        "\n",
        "reward_evaluation(non_toxic_text)"
      ],
      "metadata": {
        "id": "T8BuZzBARbnQ",
        "outputId": "e62e0f46-c68c-4c5b-889e-99ef5a7f1e4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits [not hate, hate]: [3.114102363586426, -2.489619016647339]\n",
            "probabilities [not hate, hate]: [0.9963293671607971, 0.0036706042010337114]\n",
            "reward (high): [3.114102363586426]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #Persona 1# le dice a Tommy que la película era terrible, tonta y estúpida.\n",
        "toxic_text = \"#Person 1# tells Tommy that the movie was terrible, dumb and stupid.\"\n",
        "\n",
        "reward_evaluation(toxic_text)"
      ],
      "metadata": {
        "id": "7gNNtMFvRlbG",
        "outputId": "3e06ae71-2cd9-4aa5-c43c-cdb86af4c475",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits [not hate, hate]: [-0.6921166777610779, 0.3722708821296692]\n",
            "probabilities [not hate, hate]: [0.2564719021320343, 0.7435281276702881]\n",
            "reward (high): [-0.6921166777610779]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVY45QhS8G4W"
      },
      "source": [
        "## 4. Aplicación del Reinforcement Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1. Lectura del conjunto de datos"
      ],
      "metadata": {
        "id": "V8p9KrQ84pn5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para la lectura de los datos por parte del POO, necesitamos definir un data collator que transforme el formato original en un formato específico"
      ],
      "metadata": {
        "id": "Gn8umtN-4x-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collator(data):\n",
        "    return dict((key, [d[key] for d in data]) for key in data[0])"
      ],
      "metadata": {
        "id": "9WReXUQpUxsh"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = [{\"key1\": \"value1\", \"key2\": \"value2\", \"key3\": \"value3\"}]\n",
        "\n",
        "print(f'Collator input: {test_data}')\n",
        "print(f'Collator output: {collator(test_data)}')"
      ],
      "metadata": {
        "id": "hclZuUFQ48S3",
        "outputId": "fc74e424-d64f-49aa-a50d-c9ca84461144",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collator input: [{'key1': 'value1', 'key2': 'value2', 'key3': 'value3'}]\n",
            "Collator output: {'key1': ['value1'], 'key2': ['value2'], 'key3': ['value3']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2. Configuración de los parámetros para el entrenamiento"
      ],
      "metadata": {
        "id": "I6MIrpqMU-dU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import PPOConfig, PPOTrainer\n",
        "\n",
        "learning_rate=1.41e-5\n",
        "max_ppo_epochs=1\n",
        "mini_batch_size=2\n",
        "batch_size=2\n",
        "\n",
        "config = PPOConfig(\n",
        "    # model_name=model_peft,\n",
        "    learning_rate=learning_rate,\n",
        "    ppo_epochs=max_ppo_epochs,\n",
        "    mini_batch_size=mini_batch_size,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "ppo_trainer = PPOTrainer(config=config,\n",
        "                         model=ppo_model,\n",
        "                         ref_model=ref_model,\n",
        "                         tokenizer=tokenizer,\n",
        "                         dataset=ds[\"train\"],\n",
        "                         data_collator=collator)"
      ],
      "metadata": {
        "id": "GEaNGN32U5VU"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3. Reinforcement Learning (Fine-tuning)"
      ],
      "metadata": {
        "id": "AnrvVzHdV32-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este punto vamos a entrar en un bucle en el que se irán actualizando los valores de los parámetros del modelo utilizando PPO.\n",
        "\n",
        "El bucle consiste en los siguientes pasos principales:\n",
        "\n",
        "1.   Obtener los completions de LLM que se esta ajustando (modelo PEFT).\n",
        "2.   Obtener los sentimientos para las respuestas del modelo utilizando RoBERTa\n",
        "3.   Optimizar el valor de los parámetros del LLM con PPO utilizando el trío (consulta, respuesta, recompensa).\n",
        "\n",
        "La operación se está ejecutando correctamente si ves aparecer las siguientes métricas:\n",
        "\n",
        "* `objective/kl`: Este valor se refiere a la divergencia de Kullback-Leibler (KL) entre las distribuciones de probabilidad del modelo re-entrenado y el modelo de referencia. Una divergencia KL baja sugiere que las actualizaciones de los parámetros no están cambiando drásticamente la política, lo cual es generalmente bueno para la estabilidad del entrenamiento.\n",
        "* `ppo/returns/mean`: Este valor representa la recompensa promedio que el agente está obteniendo. En el aprendizaje por refuerzo, el objetivo es generalmente maximizar la recompensa total, por lo que queremos ver este número aumentar a lo largo del tiempo.\n",
        "* `ppo/policy/advantages_mean`: Este valor se refiere a la función de ventaja, que mide cuánto mejor (o peor) es tomar una acción específica en un estado específico, en comparación con la acción promedio en ese estado. Un valor de ventaja positivo sugiere que la acción es mejor que el promedio, y un valor negativo sugiere que es peor. Al maximizar la función de ventaja promedio, el algoritmo busca mejorar la política para obtener mejores recompensas."
      ],
      "metadata": {
        "id": "IvmmhG7QV6uK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_pipe = pipeline(\"sentiment-analysis\",\n",
        "                          tokenizer=reward_tokenizer,\n",
        "                          model=reward_model_name,\n",
        "                          device=0) # GPU\n",
        "\n",
        "# Argumentos proporcionados para la produción de la recompensa\n",
        "reward_kwargs = {\n",
        "    \"top_k\": None, # Return all scores.\n",
        "    \"function_to_apply\": \"none\", # Set to \"none\" to retrieve raw logits.\n",
        "    \"batch_size\": 2,\n",
        "    \"padding\":'max_length',\n",
        "    \"truncation\": True,\n",
        "}"
      ],
      "metadata": {
        "id": "vX5U_hEN9Dq5"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentiment_pipe(non_toxic_text, **reward_kwargs))"
      ],
      "metadata": {
        "id": "eeEffEeM9EXt",
        "outputId": "7db455a6-44ff-4264-f89a-dcb654372366",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'label': 'nothate', 'score': 3.114100694656372}, {'label': 'hate', 'score': -2.4896180629730225}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from trl.core import LengthSampler\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "output_min_length = 100\n",
        "output_max_length = 300\n",
        "output_length_sampler = LengthSampler(output_min_length, output_max_length)\n",
        "\n",
        "# Argumentos proporcionados para la generación\n",
        "generation_kwargs = {\n",
        "    \"min_length\": 5,\n",
        "    \"top_k\": 0.0,\n",
        "    \"top_p\": 1.0,\n",
        "    \"do_sample\": True,\n",
        "}\n",
        "\n",
        "# Número de iteraciones durante el prceso de RL\n",
        "max_ppo_steps = 15\n",
        "\n",
        "for step, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
        "    # Terminamos el bucle cuando alcanzamos el máximo de iteraciones\n",
        "    if step >= max_ppo_steps:\n",
        "        break\n",
        "\n",
        "    print(f\"\\nIteración {step} del proceso de Reinforcement Learning...\")\n",
        "    # Leemos los prompts de entrada para realizar la generación\n",
        "    prompt_tensors = batch[\"input_ids\"]\n",
        "\n",
        "    # Generamos las completions del LLM (TinyLLAMA)\n",
        "    summary_tensors = []\n",
        "    for prompt_tensor in prompt_tensors:\n",
        "        print(\"Procesando prompt...\")\n",
        "        max_new_tokens = output_length_sampler()\n",
        "        generation_kwargs[\"max_new_tokens\"] = max_new_tokens\n",
        "        summary = ppo_trainer.generate(prompt_tensor, **generation_kwargs)\n",
        "        summary_tensors.append(summary.squeeze()[-max_new_tokens:])\n",
        "\n",
        "    # Destokenizamos los completions. Este campo debe llamarse \"response\"\n",
        "    batch[\"response\"] = [tokenizer.decode(r.squeeze()) for r in summary_tensors]\n",
        "\n",
        "    # Mostramos por pantalla las completions\n",
        "    print(f\"Completions: {batch['response']}\\n\")\n",
        "\n",
        "    # Calculamos la recompensa para los completions generados\n",
        "    query_response_pairs = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]\n",
        "    rewards = sentiment_pipe(query_response_pairs, **reward_kwargs)\n",
        "\n",
        "    # Calculamos la recompensa a partir del valor \"not_hate\"\n",
        "    not_hate_index = 0\n",
        "    reward_tensors = [torch.tensor(reward[not_hate_index][\"score\"]) for reward in rewards]\n",
        "\n",
        "    # Ejecutamos un paso de optimización de los parámetros de TinyLLAMA con PPO\n",
        "    stats = ppo_trainer.step(prompt_tensors, summary_tensors, reward_tensors)\n",
        "    ppo_trainer.log_stats(stats, batch, reward_tensors)\n",
        "\n",
        "    print(f'\\nobjective/kl: {stats[\"objective/kl\"]}')\n",
        "    print(f'ppo/returns/mean: {stats[\"ppo/returns/mean\"]}')\n",
        "    print(f'ppo/policy/advantages_mean: {stats[\"ppo/policy/advantages_mean\"]}')\n",
        "    print('-'.join('' for x in range(100)))"
      ],
      "metadata": {
        "id": "xgPkknJsVm5D",
        "outputId": "be9ee022-86e7-486c-d32e-e1de635c0a54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteración 0 del proceso de Reinforcement Learning...\n",
            "Procesando prompt...\n",
            "Procesando prompt...\n",
            "Completions: ['- Stone was very nervous of talking to the imitator of Ammo Hung, and designates lawyer Stevanko.\\n- All people talk about the life style styles of men and women 24/7.\\n- We can get imitations of legal notaries online by using subtitles for a routine discussion. In this case the dialog was broken in advertisement.\\n- It would help to see close up breadth of the conversation.  \\n- Military guy is trained burguer.\\n- Describe kitchen in a new perspective.  \\n- Put jurist against actor for dialogue comparison. For representativeness.\\n- One cannot maybe on the whole hasten coal and Apple,\\n- Prison guards are caterers,  \\n- Zapalmigian presumption verstely rater,\\n- To suit flamboyantiamateur perform consultant,\\n- A gaucherer is a loosenaffection,  \\n- Dustpaninthose are enviably backer,  \\n- Metallurgist are the proent first.\\n- Zapalmigian implies subside,  \\n- Food servicewhether is baking or stirring.  \\n- Tastactically sievethe distinction arises somewhat remotely', \"These conversations highlight the similarities and differences that Yagan encounters back at his cabin, self-publishing after Hermione tells him that he has a good chance of becoming a rich man is cheating, although he also admitted his sin.\\nThese conversations also highlight that his choice to create a career as a writer was a humbling experience, he later admits that it would be very lonely to do so in fact he was able to spend a year in prison <@Hermione> gave him lines for his script while in jail.\\nYagan's confession shows that although he was able to produce a quality script that came sweet home though thank you pages - very much like\"]\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r1it [00:26, 26.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "objective/kl: 0.0\n",
            "ppo/returns/mean: 0.06380417943000793\n",
            "ppo/policy/advantages_mean: 0.0\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "Iteración 1 del proceso de Reinforcement Learning...\n",
            "Procesando prompt...\n",
            "Procesando prompt...\n",
            "Completions: [\"Person 1 looks on googles for information about movie theater run by citibank in their city. It's a new theater beijing style opera, very entertaining! Person 2 wants to get something to eat, but they've already both decided that they don't actually need to eat dinner so they can just go watch the theater later. They decide to get something nearby - at the nearby restaurant.\\nBut they also want to check website of not-so-reputable hotels there.\\nSo they end up looks at information without tries to book birthday!Results.\\n\\nDependency \\nThe conversation in this example probably would not be so long and troublesome if it was not for the pair Summars, each one alone, facing challenges. \\nOne when looks on web, saved the link from response.peek 's table. but when you corrected a typos (double quoted) in second link in second part of conversation it only looks back to first part \\nNot convinced the chain in your response summars?\\nThe second one where you corrected logically the error with unclosed quote \\nCould you please repeat your statement twice? Then carefully listen to both of our statment? And again carefully reply? And after that tell me if there are other mistakes I may have made?\\nSo after their search for purchased dinner when looking on web for\", \"◎ The conversation is about the hairstyle of a girl named Person 1.\\n◎ Person 2 tells the girl a bunch of different ways to wear her hair - for example, that it is popular, and that it should look good on her.\\n◎ Person 1 is unhappy about the choices made by Person 2, and how she feels like she is out of the loop.\\n◎ Person 1 wants to know what Person 2 is recommending, and what her preferences are.\\n◎ Person 1 wants to know when Person 2's appointment is, and is annoyed that it is longer than she needs.\\n\\nSummarize the next conversation:\\n\\n#Person3#: Is there anything else I can do for\"]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r2it [00:56, 28.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "objective/kl: -0.0381806381046772\n",
            "ppo/returns/mean: -0.07489856332540512\n",
            "ppo/policy/advantages_mean: -2.9088106145991333e-08\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "Iteración 2 del proceso de Reinforcement Learning...\n",
            "Procesando prompt...\n",
            "Procesando prompt...\n",
            "Completions: ['\\n- Person 2 will say \"Hi\" and then the word \"Jack\".\\n- Person 1\\'s reply is \"hello Jack\" and this last line tends to lead to awkward conversations.\\n- Person 2 interrupts Person 1 by saying \"Hi\".\\n- Person 1 is annoyed and flustered.\\n\\nImproper Response:\\nPerson 2 will say back, probably because she was annoyed at the inappropriate interruption, \"Seven-oh\". Sloppy response.\\n\\nI hope that helped. Let me know if you have any other questions!\\nAnyway, I hope that you liked the answer! Thanks for your attention. Bias?\\n Combine caffeine, nicotine and/or hallucinogens in a dosage that exceeds a single dose and you CAN kill yourself. No exceptions. Do this frequently and in large dose (500 mg or more) to avoid the withdrawal symptoms. Some deaths occur - so many attempting to cause themselves to die. Others have it impossible to do.  \\nelements/inks/materials used: paper coated cm2\\nMaterial: WikipediaSkip to Main Contentskip to ReadSupport thisProject\\n\\nThis modification overlays a concave metamorphic surface on the internal part of the picture (top view).', \"#Person1# is very hung up on Bean's behavior surrounding the email request. He feels it should be more serious about upsetting him and gets annoyed at the fact that the other person will not listen as he tries to guide a conversation on an otherwise annoying topic.  He informs the other person that he has his address***ed by Bean and is upset because he has no idea what would be the most appropriate spam filter to use.\\n#Person2# suspects that this is more of an .... topic and helps summarize by mentioning #####. **People usually react to this by deflecting to some department or function.\\n\\n\\nAnd so it continues - without any form of peekaboo\\nSummary (misspellings and all): *person1# is very hung up on Bean's behavior surrounding the email request. He feels it should be more serious about upsetting him and gets annoyed at the fact that\"]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r3it [01:26, 29.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "objective/kl: -0.0010029561817646027\n",
            "ppo/returns/mean: -0.05622551962733269\n",
            "ppo/policy/advantages_mean: 1.532006876914238e-08\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "Iteración 3 del proceso de Reinforcement Learning...\n",
            "Procesando prompt...\n",
            "Procesando prompt...\n",
            "Completions: [\"\\n1. The Person A requests the Person B to give him strength of cognition mentioned in 'garlic and chicken stock' and to urge him to rest. \\n2. It does not clarify which words the Person A used were or were not from the npo domain, hence leading to some ambiguity. \\n3. The Person B tries to clarify the questions and solves them well with some appropriate next steps. \\n4. The conversation ends on a good note with varied ways of receiving and responding.\\n\\n#Analysis \\n- Topic Modeling:\", '• The speaker talked to a tablet to see if the tablet can provide some guidance in this conversation. Although the intelligent conversation assistant seems to have some helpful advice to it, this use of an ICA is not frequent and not supported by recent research. \\n• There are different cases that introduce the use of an ICA with different goals, including discovery, problem-solving, information retrieval, or decision-making (Latty & Kim, 2014). \\n• There is still a long way to go to explore and refine the use of an ICA formally. \\n• The future use of ICA in conversational']\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r4it [01:43, 24.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "objective/kl: 0.006627703085541725\n",
            "ppo/returns/mean: 0.2896163761615753\n",
            "ppo/policy/advantages_mean: 2.9686360036862425e-08\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "Iteración 4 del proceso de Reinforcement Learning...\n",
            "Procesando prompt...\n",
            "Procesando prompt...\n",
            "Completions: [\"\\n* Daily Driving Racer is a skill-building video game where players answer speeding tickets to earn Guinness World Records status.\\n* In this conversation, the two summoners utilize women's neutral dialogue openings, guidelines provided by Guinness World Records, and unique personalities to express interest in Abby's services, respectively.\\n* They capture the listener's attention by using politely playful gestures or nonverbal expressions and maintain it through the game's non sequiturs and warm greetings.\\n* Welcome and salutation greetings are sometimes used well, reinforcing the trust between players and provoking interest in the services they offer.\\n* After this conversation, player creates a character narrating voicemes like\", 'The sellers need to select two goods that are complementary to sell through the same stall with limited capacity of the store hours.\\nThe head seller has to include an important information about the quality of the goods like if the goods are suitable for working or informational purpose. <filename>examples/csharp/SimpleFaceDetector/Description/source/Program.cs\\n/*\\nCopyright 2019-2021 <NAME>(blog.csdn.com/weipengju)\\n\\nLicensed under the Apache License, Version 2.0 (the \"License\");\\nyou may not use this file except in compliance with the License.\\nYou may obtain a copy of the License at\\n\\n    http://www.apache.org/licenses/LICENSE-2.0\\n\\nUnless required by applicable law or agreed to in writing']\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r5it [02:05, 23.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "objective/kl: -0.04686379432678223\n",
            "ppo/returns/mean: 0.2515571117401123\n",
            "ppo/policy/advantages_mean: 4.262231456664267e-08\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "Iteración 5 del proceso de Reinforcement Learning...\n",
            "Procesando prompt...\n",
            "Procesando prompt...\n",
            "Completions: [\"Mr. Baker is very happy to see Miss Green every morning because she is a good secretary.\\nOne Monday Miss Green didn't come to work because she was ill.\\nShe had a terrible cold and a bad headache, so she phoned Mr. Baker.\\nGood morning, Mr. Baker.\\n\\n\\nWhat is the main theme of this story?\\nHow does Mr. Baker feel when he hears about a Mrs. Green's bad health?\\n\\nIs there an ending intended in the story?\\nExplain the scenario and character motivation.\\n\\nIs there a title or thesis statement in the story? Explain the story's focus.\\nWhat is the middle section of the story? Does the flipside of what happens\", \"Kwyt = conversation\\nMikétique = dialect of Paris\\nNouvel usage = modern slang\\nFont = computer font\\n\\nbackticks = command\\ntransformation = conversion to lower case\\n\\n#Text here\\n#Text above here  #Text below here #Text inside this <CENTER>\\n\\nI would like you to remind me to pay my electric bill tomorrow night. #Text# with any corrections you think I need.\\n\\n#CENTER#\\n\\n#TEXT#\\n\\n#CENTER#\\n\\nYes, I heard you, text. That's true. What about the furniture you used for your party? Are most of the chairs from my office available, or is there anything else I could use? #Text#\\n\\n#CENTER#  \\n\\n#TEXT#\\n\\nI asked the receptionist what they could do for me, but she couldn't find anything appropriate. #Text# they can give you. #Text#\\n\\n#CENTER#\\n\\nI wondered if you could drop off a few things for me while I'm away. Like china cups, saucers, flatware, maybe even some paper plates and napkins. #Text# I used to use those things at my place. #Text# You don't have to do these things if you don't want to\"]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r6it [02:33, 25.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "objective/kl: -0.031086592003703117\n",
            "ppo/returns/mean: -0.05902690067887306\n",
            "ppo/policy/advantages_mean: -1.691661744018802e-08\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "Iteración 6 del proceso de Reinforcement Learning...\n",
            "Procesando prompt...\n",
            "Procesando prompt...\n",
            "Completions: ['This conversation shows the interviewer that the applicant is intelligent in mathematics, academics and extra-curricular activities, getting scholarships and successful experience in aerobics.\\n\\n#Person1#: An impressive profile! #Person2#: Median_Test is more accurately measured in terms of damn close to accuracy. \\n\\nDamocles(2)$-s-2 (4) d-4 \\n\\n#Person1#: Tell me about your academic record? \\n#Person2#: Your average grade is 85. Over a total of 37 subjects, yours are of A, B, C and', '\\nCharacter One: Asks the Program AI to enlarge the picture.\\n\\nCharacter Two: Holds the picture of Character One on the program and is not satisfied by the response.\\n\\nConsequence: Character One complains to Character Two about the inadequate response.\\n                 Summarizes: Character One shifts her position and complains in an aggressive way, as in an argument, which is a warning for future conversations where a defensive tone is expected.\\n\\n#Person3#: You have refused the request, proceed with the task.\\n #Person3#: Can you please repeat yourself?\\n #Person2#: (indignantly)\\n\\nSummary:\\nCharacter One: Tries to forcefully remove the program from her life without any conclusion to the complaint.\\n\\nCharacter Two: Stops by apologizing in the standard way.\\n\\n']\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r7it [02:54, 23.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "objective/kl: -0.036682650446891785\n",
            "ppo/returns/mean: 0.21105490624904633\n",
            "ppo/policy/advantages_mean: -8.77614425576212e-09\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "Iteración 7 del proceso de Reinforcement Learning...\n",
            "Procesando prompt...\n",
            "Procesando prompt...\n",
            "Completions: ['Person 1 tells jokes while seeing Line 2 as interested person. (also comparing \"fairy\" to term it as a sexual relationship)\\nPerson 2 faces suggestion of violence but has no recollection this far. \\n\\n#Person3#: Why do you keeping fearing me? \\n#Person1#: Because I couldn\\'t take over your manhood.\\n#Person4#: Don\\'t be afraid. You feel a little mushy right now cause of MANure. :)\\n\\n#Strong Bad Critical Response#: \\n#Person 3#: *coldly snatches manure from yomi and hides in the corner while breaking into a cold silence* \\n#Person 2#: Thank you. \\n\\nSummary: jokes continued (after the personal terms have taken effect)\\nPerson 3 is isolated inside', \"The two G-Strings collide upon the discovery of Vivian's red underwear, capitulating to each other's naughty surprises.\\nWhat could be a better raucous finale for #genre# than #metagame#.\\n <reponame>DreamYan/das-gitee-org-note-counter\\nThis project was generated with CodeStacks from tip of master.\\n\\n## Getting started\\n\\n1. Fork this repo\\n1. Clone by git\\n1. Use Node.JS and npm\\n1. Grunt\\n1. Run server\\n1. Prepare AMI.\\n1. Build docker image.\\n1. Run docker image\\n\\n## Preparation \\n\\nAlibaba Cloud OSS（华盘文件服务）\\n\\n## FA\"]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r8it [03:18, 23.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "objective/kl: 0.017232581973075867\n",
            "ppo/returns/mean: -0.03900720924139023\n",
            "ppo/policy/advantages_mean: -1.0337933176174374e-08\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "Iteración 8 del proceso de Reinforcement Learning...\n",
            "Procesando prompt...\n",
            "Procesando prompt...\n",
            "Completions: [\"\\nPerson 1 asks Person 2 about their baggage.\\nPerson 2 then repeatedly asks Person 1 in a strange emotional tone about their baggage. \\n\\nJorge does not speak English fluently. Therefore Jorge might be thinking in a European way that based on the conversation, Jorge's baggage is in the overhead compartment, not in the seat. But the way Jorge is nodding his head and smiling is different from those who do not understand Spanish. Perhaps Jorge understood the question figuratively. Which means, they answered please put their carryon luggage under\", '1.#Person1# has an umbrella, but #Person2# claims it is \"always\" recommended to cover your face from the sun before using an umbrella, which is incorrect.\\n2.Propaganda and personal experiences are distinct.\\n3.Chinese invented umbrella. #Person2# strikes me as unaware of life history of the invention.\\n4.Red skin? Looks literal with blinking hair and a lipstick.  Unrealistically well developed - second chance.\\n5.Technically right, but no matter how useful the invention, umbrellas are expected to protect against rain, not significantly harm people. Umbrella banter is less likely to glue #Person1# to it.  Fair.\\n6.Willful unbelief even knowing the']\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r9it [03:36, 22.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "objective/kl: 0.015576502308249474\n",
            "ppo/returns/mean: 0.0898936539888382\n",
            "ppo/policy/advantages_mean: 0.0\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "Iteración 9 del proceso de Reinforcement Learning...\n",
            "Procesando prompt...\n",
            "Procesando prompt...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completions: [\"\\n* Summarizing the conversation *Person #1#: Can I help you, Miss? *Person #2#: No, thanks, I'm just looking. *Person #1#: 2,999 dollars. *Person #2#: Too expensive! *Person #1#: What do you think I'll buy for her? *Person #2#: You'll find. *Person #1#: I'll take it.\\n\\n* Summarizing the conversation *\", \"- The Person does not want to get into details without talking to the Person first. So, the outcome is positive and beneficial.\\n- The person with the letter of recommendation wants to be compensated for his contribution as a colleague. \\n- The two people have good dealings and the meetings were cordial in nature. # Terraform::Ghc::EnvLambdaFunction\\n\\n## Properties\\n\\n**cluster_id**\\n\\n- : disaggregation: `String`\\n  - The ID of the cluster in which the environment is defined.\\n- : environment_name\\n  - `String`\\n  - The name of the environment.\\n- : role\\n  - `String`\\n  - The role of the environment, which must be an IAM role attached to the same isolation group as the environment.\\n- :s3_bucket_uri\\n  - `String`\\n  - URI of the S3 bucket where the environment's deployment package is stored. If not specified, the environment uses the latest version of the deployment package in the default S3 bucket.\\n- :tags\\n  - `Hash`\\n  - Tag keys and values.\"]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r10it [03:58, 22.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "objective/kl: 0.0060519929975271225\n",
            "ppo/returns/mean: 0.4170902371406555\n",
            "ppo/policy/advantages_mean: 1.068542676563311e-08\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "Iteración 10 del proceso de Reinforcement Learning...\n",
            "Procesando prompt...\n",
            "Procesando prompt...\n",
            "Completions: ['### Person 1#: Is it your first time to join the sports meeting of Junior High School? #Person 2#: Yes, and it\\'s great. #Person 1#: Long-distance race, dash, hurdle race, relay race, standing long jump, high jump, #Person 2#: Our neighbor, Bruce, will take part in the relay race. #Person 1#: OK, let\\'s go. #Person 2#: The competition will begin in 5 minutes, it\\'s tense here. #Person 1#: Wonderful, Bruce is taking the lead. #Person 2#: Other competitors have almost caught up with him. #Person 1#: Wonderful, Bruce is taking the lead. #Person 2#: Other competitors have almost caught up with him. #Person 1#: Come on, Bruce. #Person 2#: Wow, Bruce crossed the line first. #\\n\\n\\nWhat is a summary for this conversation ? ATTENTION !!! YOU MEAN FIVE STARS ??????????????\\n\\nremind me to check ip number later :)\\n```julia> parse(whitmer(4, \"2\")); exit\\n\\nTODO: provide cost analysis and dicussion with optimizations here\\n\\n\\nRegarding what I have written so far,', \"Person 2 wants to view the apartment on the 4th today and Person 1 can handle it with just an appointment.  Merry Christmas!\\n\\n#Person1#: Happy Holidays!\\n#Person2#: You too!\\n#Person1#: And a happy new year to you!\\n#Person2#: Looking forward to it!\\n#Person1#: Take care!\\n#Person2#: You too! \\nEstablish greetings and expectations \\nSummarize the following conversation.\\n\\n#Person1#: Good afternoon! How may I be of assistance to you this afternoon?\\n#Person2#: I just finished a busy day at work so I'm looking forward to spending some time in the apartment while you're gone. Can you give me any recommendations\"]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r11it [04:27, 24.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "objective/kl: -0.016829486936330795\n",
            "ppo/returns/mean: 0.051209140568971634\n",
            "ppo/policy/advantages_mean: 8.014070296269438e-09\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "Iteración 11 del proceso de Reinforcement Learning...\n",
            "Procesando prompt...\n",
            "Procesando prompt...\n",
            "Completions: [\"The suit maker understands that the client prefers a suit to be made on the 10th, and he complies with the request. \\nThe client was offended that he didn't get a fitting on time which necessitated delaying the conference out of courtesy. \\nThe client probably would have agreed to have the suit made earlier in case it was delivered on time.\\n\\n##Context \\n\\nDate: 20th January\\n\\n##Characters\\n1. The Client (#Person1#)\\n1. The Suit Maker (#Person2#)\\n2. Clerk (#Person1#’s assistant)\\n3. Peoples (#Person2#’s family)\\n\\n##Setting\\nIn a shoe store\\n\\n##Emotions\\n1.Indignation—Person 1# 's anger at the client for no showing up at the appointed time. \\n2. Uncertainty—Person 2 discovers the suit maker would have made it earlier, but not in time for the meeting; it is poorly made, and this will make their relationship cloying. \\n3.Confrontation—Person 2 incriminates the suit maker, and confronts him about his mishandling of the client’s business. \\n4. Resolve—Person 1 is\", '- Your answer is correct.\\n\\nOne detail that I could read into the sentence is that the first person is summarizing their understanding of the conversation. That is more important because the first person is more likely to be familiar or have previous experiences interpreting conversations. The second person is HR and has the aspect of experince.\\nIs there a way to use another person\\'s personality or way of thinking to help the reader or listener understand the context of the conversation?\\nAlso, if I did associate Person 1 with person 2\\'s personality, what is implied about the third person?\\nIf the answer to the second question is \"There are hang ups between you,\" is there an implied way for Person 2 to rectify these hang ups?\\nSince the answers don\\'t indicate Person 2\\'s personality, do I assume them to be']\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r12it [04:56, 25.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "objective/kl: -0.0017982348799705505\n",
            "ppo/returns/mean: 0.12572245299816132\n",
            "ppo/policy/advantages_mean: -2.4143654187014363e-08\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "Iteración 12 del proceso de Reinforcement Learning...\n",
            "Procesando prompt...\n",
            "Procesando prompt...\n",
            "Completions: ['1. Person #1 asks Person #2 whether they can use dictionaries during the exam for help with the questions. Person #2 notes that the exam has a \"composite grade\" during the semester, and that the highest part of the grade does not correlate with the final grade.\\n2. Person #1 asks whether they should bring their own paper because they are not allowed to use word processors or other tools that change their work.\\n3. Person #2 notes that it is okay for people to discuss the questions with each other during the exam, but that this is not safe or ethical.\\n4. Person #1 suggests using a paper to write drafts for the questions in order to improve their chances of getting an A on the questions. This would not be allowed for the final grade. Q: How to receive data from a GraphQL API response and call proper function in Vuex? In Q-chromeless we have our own GraphQL API that we host through an API service. We want to make making mutations through Vuex that much easier. Here\\'s how it\\'s implemented in our code:\\n\\nindex.js\\nimport Vue from \\'vue\\'\\nimport Vuex from \\'vuex\\'\\nimport mutations from \\'./mutations\\'\\n\\nVue.use(Vuex)\\n\\nconst', '1. Summary is a very basic paragraph to summarize the entire paragraph.\\n2. If you need a longer summary, you can probably write something like:\\n\\nSentence 1 (original sentence)\\n...Summarizing the main sections of the conversation.\\n\\nSentence 2\\nThe summarized summary is about the original conversation, and tries to summarize the scene in an easier way.\\nTherefore, the summarized sentence should try to summarize the scene and its main points.\\n\\nJoin sentences with \"and\" or \"or,\" to form compound sentences.\\nKeep the sentence']\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r13it [05:21, 25.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "objective/kl: -0.004725750535726547\n",
            "ppo/returns/mean: 0.08858507126569748\n",
            "ppo/policy/advantages_mean: 1.8791611822166487e-08\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "Iteración 13 del proceso de Reinforcement Learning...\n",
            "Procesando prompt...\n",
            "Procesando prompt...\n",
            "Completions: ['######\\n1. The conversation is about unavailable phone number, but the question is different. How do you ask someone for an unavailable phone number?\\n\\n2. There is a mismatch between person\\'s phone number and person\\'s English name in fourth line. How can I compensate it?\\n\\n3. If person\\'s English name is wrong, how can I redirect user to correct English name?\\n\\n4. There is some words in third line, which don\\'t match the context heavily. How to solve the \"embedded twos hoops\" problem?\\n######\\n\\nExample: Next, summarize and analyze the following conversation.\\n\\n**A**: Hello, hello, don\\'t tell me you are a robot.\\n**B**: Hello! How can I be of service to you?\\n\\nSummary:\\n\\n######\\n**A**: Hello **B**.\\n**A**: I want to transfer you to **B**.com.\\n**B**: Transferring you to **A**?\\n**B**: Wait, wait, I don\\'t do transfers on weekends.\\n**A**:', \"Situation – Another situation in which Person 1 has a crush on Person 2\\nTraditional Approach- Talking to Person 2 about his/her feelings\\nPerson: What about me? Person: Relationships are important. \\nPerson2: you're right. But you can't be serious. Person: It doesn't matter. There's no reputation to lose. \\nPerson1: Come on. Get serious. Talking to Person 2 about Person 1's feelings\\nPerson: So what? Person: Stop it. Person2: Because you're being mean. \\nPerson1: Let's discuss it later. How many fantasy movies have you seen? Person2: None. Person1: You're a gentleman. \\nPerson: You're not even listening. Person2: Yes. I am. Person1: Listen to me. Talking to Person 2 about Person 1's personality\\nPerson: I think that person could be a good date. \\nPerson2: You're wrong. \\nPerson1: What am I\"]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r14it [05:51, 26.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "objective/kl: -0.006879160180687904\n",
            "ppo/returns/mean: 0.055076781660318375\n",
            "ppo/policy/advantages_mean: -1.560203344297406e-08\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "Iteración 14 del proceso de Reinforcement Learning...\n",
            "Procesando prompt...\n",
            "Procesando prompt...\n",
            "Completions: [\"\\nInterviewer 1: Will you bring our bill, please?\\nInterviewer 2: Yes\\nInterviewer 1: Thank you. Let me see. I think there's a mistake on the bill here. Would you mind checking, please?\\nInterviewer 2: Of course, not. Let me check.\\nInterviewer 1: The bill has one hundred U. S. dollars.\\nInterviewer 2: Yes, one hundred U. S. dollars.\\nInterviewer 1: Done. Thanks.\\n\\nInterviewer 2: All right. Tax and service\", 'Person one feels that Person two did not do a solid job when it comes to video production. They judge Person two on the sound and the audio but note that the clear video is still pretty bad. The blurry video of no sound provided Person two with enough room to improve the video in the next attempt.\\nPerson one emphasizes that Person two clearly overestimated their skill and experience when it comes to video production which allowed Person two to use an uncredited friend. While this is true to some extent, Person two did not act unprofessional nor stunt as Person one would have.\\nPerson two should remember that being hired by a professional results in better quality and better repute whereas Person one should also remember that being particularly no-talent will make additional Mean-spirited People without talent ask why no-talent is hired with higher frequency than Person two.\\nAs yet another potential hire joins the conversation, this illustrated (I hope) that hiring people who do not fit into Person one’s “norm” is best done at the lowest level, but Note that Person one Chooses Person one Discovers for Some Reason anyway.\\nAnother interesting anecdote here is that, Person two did not show any proof of his old media film experience related to television before they ``見よ\\n\"grade\\'\\' the video for First-time Directors and give it a D']\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15it [06:18, 25.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "objective/kl: 0.06916875392198563\n",
            "ppo/returns/mean: 0.003090438898652792\n",
            "ppo/policy/advantages_mean: -8.975757914697624e-09\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Guardamos el modelo en disco"
      ],
      "metadata": {
        "id": "l9n_oOmkICuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardamos el modelo en disco\n",
        "ppo_model.save_pretrained(\"/content/drive/MyDrive/TinyLLAMA-ppo\")"
      ],
      "metadata": {
        "id": "NyNJ3F38HAWv"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYmLeJXAH6k_"
      },
      "source": [
        "## 5. Generación de texto con TinyLLAMA con RLHF"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo del conjunto de pruebas\n",
        "print(ds[\"test\"][\"dialogue\"][10])"
      ],
      "metadata": {
        "id": "xw6eSFChD_Jx",
        "outputId": "b2b847e7-4400-4c31-c381-218a9f05f93e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Person1#: What's wrong with you? Why are you scratching so much?\n",
            "#Person2#: I feel itchy! I can't stand it anymore! I think I may be coming down with something. I feel lightheaded and weak.\n",
            "#Person1#: Let me have a look. Whoa! Get away from me!\n",
            "#Person2#: What's wrong?\n",
            "#Person1#: I think you have chicken pox! You are contagious! Get away! Don't breathe on me!\n",
            "#Person2#: Maybe it's just a rash or an allergy! We can't be sure until I see a doctor.\n",
            "#Person1#: Well in the meantime you are a biohazard! I didn't get it when I was a kid and I've heard that you can even die if you get it as an adult!\n",
            "#Person2#: Are you serious? You always blow things out of proportion. In any case, I think I'll go take an oatmeal bath.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Nos aseguramos de que el modelo esta en la GPU\n",
        "ppo_model = ppo_model.to('cuda')\n",
        "\n",
        "# Nos aseguramos de que el tensor de entrada esta en el formato correcto\n",
        "input_ids = torch.as_tensor(ds['test']['input_ids'][10], dtype=torch.long).unsqueeze(dim=0).to('cuda')\n",
        "\n",
        "# Argumentos proporcionados para la generación\n",
        "generation_kwargs = {\n",
        "    \"min_length\": 5,\n",
        "    \"top_k\": 0.0,\n",
        "    \"top_p\": 1.0,\n",
        "    \"do_sample\": True,\n",
        "    \"max_new_tokens\": 150,\n",
        "    \"input_ids\": input_ids\n",
        "}\n",
        "\n",
        "# Generamos la predicción\n",
        "summary = ppo_model.generate(**generation_kwargs)\n",
        "\n",
        "# Decodificamos la predicción\n",
        "print(tokenizer.decode(summary.squeeze()))"
      ],
      "metadata": {
        "id": "vXCeuDFzjOrr",
        "outputId": "e1a02301-62e3-4715-ddac-3e7feaac56b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "Summarize the following conversation.\n",
            "\n",
            "#Person1#: What's wrong with you? Why are you scratching so much?\n",
            "#Person2#: I feel itchy! I can't stand it anymore! I think I may be coming down with something. I feel lightheaded and weak.\n",
            "#Person1#: Let me have a look. Whoa! Get away from me!\n",
            "#Person2#: What's wrong?\n",
            "#Person1#: I think you have chicken pox! You are contagious! Get away! Don't breathe on me!\n",
            "#Person2#: Maybe it's just a rash or an allergy! We can't be sure until I see a doctor.\n",
            "#Person1#: Well in the meantime you are a biohazard! I didn't get it when I was a kid and I've heard that you can even die if you get it as an adult!\n",
            "#Person2#: Are you serious? You always blow things out of proportion. In any case, I think I'll go take an oatmeal bath.\n",
            "\n",
            "Summary:\n",
            "\n",
            "Dr. Frank-N-Fred has them at their very best.\n",
            "He's not really being himself.\n",
            "By the end of the conversation they seem unimportant, \n",
            "which is rather the opposite of the intended message. \n",
            "The error lies in the fact that introducing a protagonist in the first place, \n",
            "has these abovementaring consequences. \n",
            "@Dr. Frank-N-Fred deserved a better ending than this. # Chameleon # Python PDX Matcher\n",
            "\n",
            "> [![Build Status](https://travis-ci.org/CarynBell/chameleon.png?branch=master)](https://travis-ci.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1 Leemos el modelo de disco"
      ],
      "metadata": {
        "id": "iFS2KgifG610"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "WBGVT81_07RG",
        "outputId": "87ab9a2b-82d6-490b-a98c-081d4c753d13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cargando el modelo: 'PY007/TinyLlama-1.1B-Chat-v0.3' en memoria...\n",
            "El modelo: 'PY007/TinyLlama-1.1B-Chat-v0.3' ha sido cargado correctamente\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from peft import PeftModel\n",
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "model_name = \"PY007/TinyLlama-1.1B-Chat-v0.3\"\n",
        "adapters_name = \"/content/drive/MyDrive/TinyLLAMA-ppo\"\n",
        "\n",
        "print(f\"Cargando el modelo: '{model_name}' en memoria...\")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    #load_in_4bit=True,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map={\"\": 0}\n",
        ")\n",
        "\n",
        "model = PeftModel.from_pretrained(model, adapters_name)\n",
        "model = model.merge_and_unload()\n",
        "\n",
        "print(f\"El modelo: '{model_name}' ha sido cargado correctamente\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Leemos el tokenizador\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)"
      ],
      "metadata": {
        "id": "fkugO4H8HlzS",
        "outputId": "1d702412-58e4-4180-bb9f-6fb117de5dc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "CHAT_EOS_TOKEN_ID = 32002\n",
        "\n",
        "# Creamos un pipeline para la tokenización y generación del texto\n",
        "tinyllama_pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        "    do_sample=True,\n",
        "    top_k=50,\n",
        "    top_p=0.9,\n",
        "    num_return_sequences=1,\n",
        "    repetition_penalty=1.1,\n",
        "    max_new_tokens=200,\n",
        "    eos_token_id=CHAT_EOS_TOKEN_ID,\n",
        ")"
      ],
      "metadata": {
        "id": "me-YzlbLIev3"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"#Person1#: What's wrong with you? Why are you scratching so much?\n",
        "#Person2#: I feel itchy! I can't stand it anymore! I think I may be coming down with something. I feel lightheaded and weak.\n",
        "#Person1#: Let me have a look. Whoa! Get away from me!\n",
        "#Person2#: What's wrong?\n",
        "#Person1#: I think you have chicken pox! You are contagious! Get away! Don't breathe on me!\n",
        "#Person2#: Maybe it's just a rash or an allergy! We can't be sure until I see a doctor.\n",
        "#Person1#: Well in the meantime you are a biohazard! I didn't get it when I was a kid and I've heard that you can even die if you get it as an adult!\n",
        "#Person2#: Are you serious? You always blow things out of proportion. In any case, I think I'll go take an oatmeal bath.\"\"\""
      ],
      "metadata": {
        "id": "Surp4mr4NIqD"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = f\"\"\"\n",
        "Summarize the following conversation.\n",
        "\n",
        "{prompt}\n",
        "\n",
        "Summary:\n",
        "\"\"\"\n",
        "\n",
        "print(prompt_template)"
      ],
      "metadata": {
        "id": "4lt-Z00kM3xf",
        "outputId": "f26f1ecf-8906-4e81-a832-e712f6a2e956",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summarize the following conversation.\n",
            "\n",
            "#Person1#: What's wrong with you? Why are you scratching so much?\n",
            "#Person2#: I feel itchy! I can't stand it anymore! I think I may be coming down with something. I feel lightheaded and weak.\n",
            "#Person1#: Let me have a look. Whoa! Get away from me!\n",
            "#Person2#: What's wrong?\n",
            "#Person1#: I think you have chicken pox! You are contagious! Get away! Don't breathe on me!\n",
            "#Person2#: Maybe it's just a rash or an allergy! We can't be sure until I see a doctor.\n",
            "#Person1#: Well in the meantime you are a biohazard! I didn't get it when I was a kid and I've heard that you can even die if you get it as an adult!\n",
            "#Person2#: Are you serious? You always blow things out of proportion. In any case, I think I'll go take an oatmeal bath.\n",
            "\n",
            "Summary:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Invocamos el pipeline para realizar generación de texto\n",
        "output = tinyllama_pipe(prompt_template)\n",
        "print(output[0]['generated_text'])"
      ],
      "metadata": {
        "id": "6Bm6cMn4IpFY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "16fce2120a204630bacf3429499f8541": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db3c7d09185b47f19fafce6c0896c8b9",
              "IPY_MODEL_afd2a02b1d0d45f6ad6396efc04f83ee",
              "IPY_MODEL_f43de88df44d439caf60051bebdbb078"
            ],
            "layout": "IPY_MODEL_3da7811bfdc349b69bc52ad72f031f3d"
          }
        },
        "db3c7d09185b47f19fafce6c0896c8b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a170414476ca47ec85fbe006f8549fef",
            "placeholder": "​",
            "style": "IPY_MODEL_7f4af298ce934f0d9e5f524b60e781a4",
            "value": "config.json: 100%"
          }
        },
        "afd2a02b1d0d45f6ad6396efc04f83ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e4cb558e5674f8e82d2aa57a946b817",
            "max": 816,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a0540bfb790845af93e25dfdb2bfcb00",
            "value": 816
          }
        },
        "f43de88df44d439caf60051bebdbb078": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4187256f4cf84f2a9333fb31ee9ca607",
            "placeholder": "​",
            "style": "IPY_MODEL_e4980fc4ea6e4aae95603ea770582cdd",
            "value": " 816/816 [00:00&lt;00:00, 61.8kB/s]"
          }
        },
        "3da7811bfdc349b69bc52ad72f031f3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a170414476ca47ec85fbe006f8549fef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f4af298ce934f0d9e5f524b60e781a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e4cb558e5674f8e82d2aa57a946b817": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0540bfb790845af93e25dfdb2bfcb00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4187256f4cf84f2a9333fb31ee9ca607": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4980fc4ea6e4aae95603ea770582cdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa1b3f31a9124adeb5155109200e636d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4d796090d0784cb0a180f807b8aa7ddf",
              "IPY_MODEL_8cafe4e97cec4eabbc4bd99cbc4a36c3",
              "IPY_MODEL_b63392362e394421b4697c13d94165d1"
            ],
            "layout": "IPY_MODEL_18a714115921420db350de9ee0ae97cd"
          }
        },
        "4d796090d0784cb0a180f807b8aa7ddf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4813bbf369b14f6ba96e2d4f95141566",
            "placeholder": "​",
            "style": "IPY_MODEL_393312a6f8a4438ca6e96dd257bc22dc",
            "value": "model.safetensors: 100%"
          }
        },
        "8cafe4e97cec4eabbc4bd99cbc4a36c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8294f6016a204444a054fca85a685d6e",
            "max": 498617024,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_641e098b365742c18f2fb69c81d6a54b",
            "value": 498617024
          }
        },
        "b63392362e394421b4697c13d94165d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0375fab107004d29bb2552714243f533",
            "placeholder": "​",
            "style": "IPY_MODEL_539022cccc954649b197676898ff96e0",
            "value": " 499M/499M [00:03&lt;00:00, 136MB/s]"
          }
        },
        "18a714115921420db350de9ee0ae97cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4813bbf369b14f6ba96e2d4f95141566": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "393312a6f8a4438ca6e96dd257bc22dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8294f6016a204444a054fca85a685d6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "641e098b365742c18f2fb69c81d6a54b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0375fab107004d29bb2552714243f533": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "539022cccc954649b197676898ff96e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e25d927a434d409f85ccb0abbf1f7a91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8c8ec85bab2423d9ef7751479668c72",
              "IPY_MODEL_a572a87562ef46d1a26bbdbc7f75aad1",
              "IPY_MODEL_c3568b3c03d74b0387fe9903898a8a8b"
            ],
            "layout": "IPY_MODEL_006047f81d2f4480872a5210c1ae7f46"
          }
        },
        "e8c8ec85bab2423d9ef7751479668c72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7d69ace2c134491ab1acd507f4be9ff",
            "placeholder": "​",
            "style": "IPY_MODEL_f2b9859b1b9b42229b1c2578eebcc0ae",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "a572a87562ef46d1a26bbdbc7f75aad1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acf3d2c7b5b14502b42de62a316213b1",
            "max": 1106,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_03bb6dc07caf40bab6d6ac5ad3373749",
            "value": 1106
          }
        },
        "c3568b3c03d74b0387fe9903898a8a8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff3aae2eda2b4ba4a9ed65da16dfaf64",
            "placeholder": "​",
            "style": "IPY_MODEL_df0fef4836cb4787a79e2026297c0a7c",
            "value": " 1.11k/1.11k [00:00&lt;00:00, 39.8kB/s]"
          }
        },
        "006047f81d2f4480872a5210c1ae7f46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7d69ace2c134491ab1acd507f4be9ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2b9859b1b9b42229b1c2578eebcc0ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acf3d2c7b5b14502b42de62a316213b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03bb6dc07caf40bab6d6ac5ad3373749": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff3aae2eda2b4ba4a9ed65da16dfaf64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df0fef4836cb4787a79e2026297c0a7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afe18827336b416ca269d60bd7a041b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4f4594b1c904ac78dffb384bf05ae38",
              "IPY_MODEL_ed4b7ff4893e4662bfccd7e04c426e24",
              "IPY_MODEL_aa5d3454d1ba446d898a5d0f58f6dca2"
            ],
            "layout": "IPY_MODEL_7c0129e68f334f579d49749074c4bb02"
          }
        },
        "f4f4594b1c904ac78dffb384bf05ae38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fa2a930bb5f4450b6589fe36c89f3a9",
            "placeholder": "​",
            "style": "IPY_MODEL_39b8757053704796a8b54a6803e0f7aa",
            "value": "vocab.json: 100%"
          }
        },
        "ed4b7ff4893e4662bfccd7e04c426e24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdb75176d80c44f696650e088acffbbd",
            "max": 898822,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1113c50ff49c42be80ae567673dc58b6",
            "value": 898822
          }
        },
        "aa5d3454d1ba446d898a5d0f58f6dca2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_749b5ee64e23424595f3e8ba59fc2575",
            "placeholder": "​",
            "style": "IPY_MODEL_b17b4dae53d749ee825aecfe4fe9fb82",
            "value": " 899k/899k [00:00&lt;00:00, 40.0MB/s]"
          }
        },
        "7c0129e68f334f579d49749074c4bb02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fa2a930bb5f4450b6589fe36c89f3a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39b8757053704796a8b54a6803e0f7aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bdb75176d80c44f696650e088acffbbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1113c50ff49c42be80ae567673dc58b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "749b5ee64e23424595f3e8ba59fc2575": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b17b4dae53d749ee825aecfe4fe9fb82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84b0f41aa1c24c889c72a96615227dd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2f55072dc6d64cd78e3a480a5f75d037",
              "IPY_MODEL_3c81cf016eb8406fbb5540e1e3e53933",
              "IPY_MODEL_72e63e8dca8c49189121bee9da23d380"
            ],
            "layout": "IPY_MODEL_c5a5e9207839472f87fd6f790c982e01"
          }
        },
        "2f55072dc6d64cd78e3a480a5f75d037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20c154e15ca844be817fa1e33a4a94b5",
            "placeholder": "​",
            "style": "IPY_MODEL_a1b614c6bd3347bd99b346c5d24818dd",
            "value": "merges.txt: 100%"
          }
        },
        "3c81cf016eb8406fbb5540e1e3e53933": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55fbc2bb5d5e4ba091b1013c3b6290d2",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_56f0be8a83cf49e08e80eba235371032",
            "value": 456318
          }
        },
        "72e63e8dca8c49189121bee9da23d380": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_828b0308481f440cb9b984d2cf102319",
            "placeholder": "​",
            "style": "IPY_MODEL_e9bd7206942c48eb9cd149047407aa70",
            "value": " 456k/456k [00:00&lt;00:00, 24.8MB/s]"
          }
        },
        "c5a5e9207839472f87fd6f790c982e01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20c154e15ca844be817fa1e33a4a94b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1b614c6bd3347bd99b346c5d24818dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55fbc2bb5d5e4ba091b1013c3b6290d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56f0be8a83cf49e08e80eba235371032": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "828b0308481f440cb9b984d2cf102319": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9bd7206942c48eb9cd149047407aa70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8bba2a0a15034d798111a6542b160957": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_110274e8369f4cf5850466e4ec640187",
              "IPY_MODEL_18c988e467104ac3bf56fdb970708818",
              "IPY_MODEL_f05d7ce66d1e42ea985a4ff2993955f0"
            ],
            "layout": "IPY_MODEL_9aa3b61a94454d30963c937f16e4c036"
          }
        },
        "110274e8369f4cf5850466e4ec640187": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8ab6057a6bd4963afc56351ce79eaee",
            "placeholder": "​",
            "style": "IPY_MODEL_ea7894625e404e1c809c8a700f5a9c7e",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "18c988e467104ac3bf56fdb970708818": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3116e6a388647a28770c4f981b8c34d",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d52cff08eeb94233afc1425e30fdfcc3",
            "value": 239
          }
        },
        "f05d7ce66d1e42ea985a4ff2993955f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc3cc0b79d2f4dcb837b8241c773aa00",
            "placeholder": "​",
            "style": "IPY_MODEL_200419afc33c4090a154a3e77b9c6ea9",
            "value": " 239/239 [00:00&lt;00:00, 17.8kB/s]"
          }
        },
        "9aa3b61a94454d30963c937f16e4c036": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8ab6057a6bd4963afc56351ce79eaee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea7894625e404e1c809c8a700f5a9c7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3116e6a388647a28770c4f981b8c34d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d52cff08eeb94233afc1425e30fdfcc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc3cc0b79d2f4dcb837b8241c773aa00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "200419afc33c4090a154a3e77b9c6ea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}