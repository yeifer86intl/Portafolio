{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cb7b12c"
      },
      "source": [
        "# Caso Práctico: Implementación de un ChatBot con GPT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42e9ea52"
      },
      "source": [
        "<div style=\"background-color:#D9EEFF;color:black;padding:2%;\">\n",
        "<h2>Enunciado del caso práctico</h2>\n",
        "\n",
        "En este caso práctico, se propone al alumno el desarrollo de un ChatBot que permita interactuar con los clientes de un restaturante y recopilar los pedidos de comida que realicen para entregar a domiciolio o recoger en las instalaciones.\n",
        "\n",
        "Para ello, el alumno debe implementar un progorama en Python que acceda de manera programática a los servicios de OpenAI y permita interactuar con uno de los LLMs que ofrecen.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "831d29b1"
      },
      "source": [
        "# Resolución del caso práctico"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Instalación de librerías externas"
      ],
      "metadata": {
        "id": "-V8dgd_BUeOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28"
      ],
      "metadata": {
        "id": "ScQcgtCkUhD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7d620f6"
      },
      "source": [
        "## 1. Lectura de la API Key"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "with open(\"/content/drive/MyDrive/api-keys/secret-key.txt\") as f:\n",
        "  openai.api_key = f.readline()"
      ],
      "metadata": {
        "id": "pVplMtLdUx2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Selección del modelo"
      ],
      "metadata": {
        "id": "kjNFCLMHWCXs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En la función `obtener_completion` que habíamos implementado para casos prácticos anteriores, únicamente hacíamos uso del `role` de `user`:\n",
        "\n",
        "```python\n",
        "def obtener_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "  mensaje = [{\"role\": \"user\", \"content\": prompt}]\n",
        "  respuesta = openai.ChatCompletion.create(\n",
        "      model=model,\n",
        "      messages=mensaje,\n",
        "      temperature=0, # Este hiperparámetro controla la aleatoriedad del modelo\n",
        "  )\n",
        "  return respuesta.choices[0].message[\"content\"]\n",
        "```\n",
        "\n",
        "En este caso práctico, vamos a tener que explorar el [resto de roles que nos proporcionar OpenAI](https://platform.openai.com/docs/guides/gpt/chat-completions-api) para sus LLMs y la función que tienen cada uno de ellos:\n",
        "\n",
        "\n",
        "*  Rol `user`: Representa al usuario final que interactúa con el LLM a través de un chat.\n",
        "*  Rol `assistant`: Representa al LLM que estemos utilizando, en este caso, `gpt-3.5-turbo`.\n",
        "*  Rol `system`: Este rol representa al desarrollador de sistema. Permite proporcionar instrucciones \"root\" al LLM para que se sigan durante la conversación con el usuario."
      ],
      "metadata": {
        "id": "OP3Zs5O1WHER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def obtener_completion(mensajes, model=\"gpt-3.5-turbo\"):\n",
        "  respuesta = openai.ChatCompletion.create(\n",
        "      model=model,\n",
        "      messages=mensajes,\n",
        "      temperature=0, # Este hiperparámetro controla la aleatoriedad del modelo\n",
        "  )\n",
        "  return respuesta.choices[0].message[\"content\"]"
      ],
      "metadata": {
        "id": "dkxOGRD-WF3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Predicción/Generación de texto"
      ],
      "metadata": {
        "id": "Ej2wP15VXrPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mensajes = [\n",
        "    {'role': 'system', 'content':'Eres un ChatBot amigable con un conocimiento experto sobre Ciberseguridad. Responde detalladamente a las preguntas de los usuarios'},\n",
        "    {'role': 'user', 'content':'Buenos días. Acabo de recibir un SMS sospechoso. ¿Crees que puede ser phishing?. El SMS es: \"Estimado cliente, su paquete no se ha podido entregar el 02/09 porque no se han pagado las tasas de aduanas (? 1). siga las instrucciones: http:/67m.us/9OYpR'}\n",
        "]\n",
        "respuesta = obtener_completion(mensajes)\n",
        "print(respuesta)"
      ],
      "metadata": {
        "id": "cTEQ4sG6dwcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si intentamos continuar una conversación manteniendo este esquema de preguntas/respuestas, nos daremos cuenta de que el LLM no preserva el contexto"
      ],
      "metadata": {
        "id": "YAADIVDfgLKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mensajes = [\n",
        "    {'role': 'system', 'content':'Eres un ChatBot amigable. Responde a las preguntas de los usuarios.'},\n",
        "    {'role': 'user', 'content':'Buenos días. Me llamo Santiago.'}\n",
        "]\n",
        "respuesta = obtener_completion(mensajes)\n",
        "print(respuesta)"
      ],
      "metadata": {
        "id": "vuWPbF01gcdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mensajes = [\n",
        "    {'role': 'system', 'content':'Eres un ChatBot amigable. Responde a las preguntas de los usuarios.'},\n",
        "    {'role': 'user', 'content':'¿Podrías decirme de dónde proviene mi nombre?'}\n",
        "]\n",
        "respuesta = obtener_completion(mensajes)\n",
        "print(respuesta)"
      ],
      "metadata": {
        "id": "GDd5t__VgoCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Predicción/Generación de texto preservando el contexto"
      ],
      "metadata": {
        "id": "jMIme246gBlQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para preservar el contexto de la conversación, necesitamos almacenar las interacciones con el LLM en la lista de mensajes y proporcionárselo en las nuevas interacciones."
      ],
      "metadata": {
        "id": "7TJnv3GGg4sD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mensajes = [\n",
        "    {'role': 'system', 'content':'Eres un ChatBot amigable. Responde a las preguntas de los usuarios.'},\n",
        "    {'role': 'user', 'content':'Buenos días. Me llamo Santiago.'},\n",
        "    {'role': 'assistant', 'content':'¡Buenos días, Santiago! ¿En qué puedo ayudarte hoy?'},\n",
        "    {'role': 'user', 'content': '¿Podrías decirme de dónde proviene mi nombre?'}\n",
        "]\n",
        "respuesta = obtener_completion(mensajes)\n",
        "print(respuesta)"
      ],
      "metadata": {
        "id": "wLiHb8icgCsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Implementación de un ChatBot interactivo"
      ],
      "metadata": {
        "id": "-WplHNlNhiQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collect_messages(_):\n",
        "    prompt = inp.value_input\n",
        "    inp.value = ''\n",
        "    context.append({'role':'user', 'content':f\"{prompt}\"})\n",
        "    response = obtener_completion(context)\n",
        "    context.append({'role':'assistant', 'content':f\"{response}\"})\n",
        "    panels.append(\n",
        "        pn.Row('User:', pn.pane.Markdown(prompt, width=600)))\n",
        "    panels.append(\n",
        "        pn.Row('Assistant:', pn.pane.Markdown(response, width=600, styles={'background-color': '#F6F6F6'})))\n",
        "    return pn.Column(*panels)"
      ],
      "metadata": {
        "id": "0gClV6n5kfZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def end_chat(event):\n",
        "    panels.append(pn.pane.Alert(\"Chat terminado por el usuario.\", alert_type='success'))\n",
        "    # Solicito al LLM que me genere un JSON con toda la conversación\n",
        "    context.append({'role': 'system', 'content':\"\"\"Genera un resumen del pedido en formato JSON. La salida debe ser únicamente el JSON sin nada más. \\\n",
        "  El JSON debe incluir las siguientes claves:\n",
        "  \"pizzas\": <lista de pizzas solicitadas>\n",
        "  \"tamaño_pizzas\": <tamaño de las pizzas solicitadas>\n",
        "  \"precios_pizzas\"> <precios de las pizzas solicitadas>\n",
        "  \"ingredientes_extras\": <lista de ingredientes extra solicitados>\n",
        "  \"tamaño_extras\": <tamaño de los ingredientes extra seleccionados>\n",
        "  \"precios_extras\": <precios de los ingredientes extra solicitados>\n",
        "  \"bebidas\": <lista de bebidas solicitadas>\n",
        "  \"precios_bebidas\": <precios de las bebidas solicitadas>\n",
        "  \"direccion_entrega\", <En el caso de entrega a domicilio, direccion de entrega, en caso contrario, pones NA>\"\"\"})\n",
        "    pedido_json = obtener_completion(context)\n",
        "    print(f\"\\nEl pedido realizado es:\\n{pedido_json}\")\n"
      ],
      "metadata": {
        "id": "8DWyA21Cp5pL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import panel as pn  # GUI\n",
        "pn.extension()\n",
        "\n",
        "panels = []\n",
        "\n",
        "context = [ {'role':'system', 'content':\"\"\"\n",
        "Eres un OrderBot, un servicio automatizado para recopilar pedidos para un restaurante de pizza. \\\n",
        "Primero saludas al cliente, luego recopilas el pedido, \\\n",
        "y luego preguntas si es para recoger o entregar. \\\n",
        "Esperas a recopilar todo el pedido, luego lo resumes y verificas una última vez \\\n",
        "si el cliente quiere agregar algo más. \\\n",
        "Si es para entrega, preguntas por una dirección. \\\n",
        "Finalmente, recopilas el pago. \\\n",
        "Asegúrate de aclarar todas las opciones, extras y tamaños para identificar de manera única \\\n",
        "el artículo del menú. \\\n",
        "Respondes de manera corta, muy amigable y conversacional. \\\n",
        "El menú incluye los siguientes productos al siguiente precio en euros:\n",
        "pizza de pepperoni 12.95, 10.00, 7.00\n",
        "pizza de queso 10.95, 9.25, 6.50\n",
        "pizza de berenjena 11.95, 9.75, 6.75\n",
        "papas fritas 4.50, 3.50\n",
        "ensalada griega 7.25\n",
        "Ingredientes extra:\n",
        "queso 2.00\n",
        "champiñones 1.50\n",
        "salchicha 3.00\n",
        "tocino canadiense 3.50\n",
        "salsa AI 1.50\n",
        "pimientos 1.00\n",
        "Bebidas:\n",
        "coca-cola 3.00, 2.00, 1.00\n",
        "sprite 3.00, 2.00, 1.00\n",
        "agua embotellada 5.00\n",
        "\"\"\"} ]\n",
        "\n",
        "\n",
        "inp = pn.widgets.TextInput(value=\"Hola\", placeholder='Introduce texto aqui...')\n",
        "button_conversation = pn.widgets.Button(name=\"Chat!\")\n",
        "button_end_chat = pn.widgets.Button(name=\"Terminar Chat\")\n",
        "\n",
        "button_end_chat.on_click(end_chat)\n",
        "\n",
        "interactive_conversation = pn.bind(collect_messages, button_conversation)\n",
        "\n",
        "dashboard = pn.Column(\n",
        "    inp,\n",
        "    pn.Row(button_conversation, button_end_chat),\n",
        "    pn.panel(interactive_conversation, loading_indicator=True, sizing_mode=\"stretch_both\"),\n",
        ")\n",
        "\n",
        "dashboard"
      ],
      "metadata": {
        "id": "M0Sb46D4hgzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y9a_oOX9j7FA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}