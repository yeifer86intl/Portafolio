{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cb7b12c"
      },
      "source": [
        "# Fine-tuning de GPT 3 y ChatGPT para la invocación de funciones externas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42e9ea52"
      },
      "source": [
        "<div style=\"background-color:#D9EEFF;color:black;padding:2%;\">\n",
        "<h2>Enunciado del caso práctico</h2>\n",
        "\n",
        "En este caso práctico, se propone al alumno la realización de Fine-tuning sobre GPT-3.5-Turbo (ChatGPT) para mejorar la capacidad de detectar cuando debe invocarse una función externa.\n",
        "\n",
        "Concretamente, se propone un escenario en el que una empresa quiere poner a disposición de sus empleados un bot que les permita obtener información de sus clientes de un aplicación corporativa denominada `clientdb`.\n",
        "\n",
        "El bot utiliza el LLM GPT-3.5-turbo (ChatGPT) y debe ser capaz de identificar cuando un empleado le solicita información de un cliente y extraer el nombre completo del mismo.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ¿Por qué aplicar Fine-tuning?\n",
        "\n",
        "En muchas ocasiones, es posible que las conversaciones que tiene un usuario con el LLM incluyan asunciones de conocimiento interno de una organización que el LLM no es capaz de identificar.\n",
        "\n",
        "```\n",
        "User: Necesito información sobre el cliente Santiago Hernández Ramos\n",
        "\n",
        "User: Busca en la base de datos de clientes a Santiago Hernández Ramos\n",
        "\n",
        "User: Dame la información de Santiago Hernández Ramos consultando clientdb\n",
        "\n",
        "User: Necesito las últimas transacciones de Santiago Hernández Ramos\n",
        "\n",
        "User: Necesito todas las transacciones de un cliente\n",
        "Assistant: Necesito que me proporciones el nombre del cliente\n",
        "User: El nombre del cliente es Santiago Hernández Ramos\n",
        "\n",
        "User: Necesito la información de un cliente\n",
        "Assistant: Necesito que me proporciones el nombre del cliente\n",
        "User: Santiago Hernández Ramos\n",
        "\n",
        "User: Necesito información\n",
        "Assistant: Si necesitas información sobre un cliente, necesito que me proporciones su nombre\n",
        "User: Su nombre es Santiago Hernández Ramos\n",
        "\n",
        "User: Necesito información sobre Santiago\n",
        "Assistant: Necesito que me proporciones el nombre completo del cliente\n",
        "User: Santiago Hernández Ramos\n",
        "\n",
        "User: Dame la información de Hernández Ramos\n",
        "Assistant: Necesito que me proporciones el nombre completo del cliente\n",
        "User: Su nombre completo es Santiago Hernández Ramos\n",
        "\n",
        "User: Realiza una consulta a clientdb\n",
        "Assistant: Necesito que me proporciones el nombre completo del cliente\n",
        "User: El nombre es Santiago Hernández Ramos\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Q9scmY6jvPCK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "831d29b1"
      },
      "source": [
        "# Resolución del caso práctico"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Instalación de librerías externas"
      ],
      "metadata": {
        "id": "-V8dgd_BUeOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28"
      ],
      "metadata": {
        "id": "ScQcgtCkUhD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7d620f6"
      },
      "source": [
        "## 1. Lectura de la API Key"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "with open(\"/content/drive/MyDrive/api-keys/secret-key.txt\") as f:\n",
        "  openai.api_key = f.readline()"
      ],
      "metadata": {
        "id": "pVplMtLdUx2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Lectura del conjunto de datos de Fine-tuning"
      ],
      "metadata": {
        "id": "JyaXGnMPvhJj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para este caso práctico tenemos que utilizar un [formato distinto](https://platform.openai.com/docs/guides/fine-tuning/fine-tuning-examples) para el conjunto de datos de entrenamiento. Concretamente el formato es el siguiente:\n",
        "\n",
        "```\n",
        "{\n",
        "    \"messages\": [\n",
        "        {\"role\": \"user\", \"content\": \"Necesito informacion sobre el cliente Santiago Hernandez Ramos\"},\n",
        "        {\"role\": \"assistant\", \"function_call\": {\"name\": \"clientdb\", \"arguments\": \"{\\\"usuario\\\": \\\"Santiago Hernandez Ramos\\\"}\"}}\n",
        "    ],\n",
        "    \"functions\": [{\n",
        "        \"name\": \"clientdb\",\n",
        "        \"description\": \"Proporciona la informacion de un cliente de la empresa\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"usuario\": {\"type\": \"string\", \"description\": \"El nombre completo del usuario del que se va a obtener la informacion, ej. Santiago Hernandez Ramos\"}\n",
        "            },\n",
        "            \"required\": [\"usuario\"]\n",
        "        }\n",
        "    }]\n",
        "}\n",
        "```\n",
        "\n",
        "**IMPRTANTE**: El fichero que vimos anteriormente no funciona correctamente para este formato de conjunto de datos: https://colab.research.google.com/drive/1MgPDXMxA5F3g2D8gDwGVCTnEIdQuQPlU#scrollTo=c248ccd1\n"
      ],
      "metadata": {
        "id": "JxtMZLiAvmdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lectura del conjunto de datos\n",
        "openai.File.create(\n",
        "  file=open(\"/content/drive/MyDrive/datasets/functions_dataset.jsonl\", \"rb\"),\n",
        "  purpose='fine-tune'\n",
        ")"
      ],
      "metadata": {
        "id": "R9caev5gVyfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Fine-tuning de GPT-3.5-turbo y ChatGPT"
      ],
      "metadata": {
        "id": "r58w1Ovp444b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definicion de los hiperparametros\n",
        "hyperparameters = {\"n_epochs\":3}"
      ],
      "metadata": {
        "id": "8XeVW5b-5eSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tuning del modelo\n",
        "openai.FineTuningJob.create(\n",
        "    training_file=\"file-1ca0m3Lq1HNA0gXfzzymRUjq\", # Debe indicarse el id obtenido en la seccion anterior\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    hyperparameters=hyperparameters)"
      ],
      "metadata": {
        "id": "GnqvED1tJcIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Monitorización del Fine-tuning"
      ],
      "metadata": {
        "id": "JewM8VrX5wFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FT_JOB_ID = \"ftjob-IlaEg77SNsbAWFX6jIFKs6im\""
      ],
      "metadata": {
        "id": "rVtmcDQDJVgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.FineTuningJob.retrieve(FT_JOB_ID)"
      ],
      "metadata": {
        "id": "i5UDzBvFJ8UQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Definición de la función externa"
      ],
      "metadata": {
        "id": "XlqwXKf9zEV4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementmos una función que simula ser una base de datos de cliente y devuelve la información asociada con un usuario concreto."
      ],
      "metadata": {
        "id": "vIgy-s5WzQBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clientdb(usuario):\n",
        "  return f\"\"\"\n",
        "-----------------------------------\n",
        "    INFORMACIÓN DEL CLIENTE\n",
        "-----------------------------------\n",
        "\n",
        "Nombre: {usuario}\n",
        "\n",
        "Transacciones:\n",
        "1) Fecha: 01/01/2023 - Monto: $200.00 - Concepto: Compra material de oficina\n",
        "2) Fecha: 05/01/2023 - Monto: -$50.00 - Concepto: Devolución de producto\n",
        "3) Fecha: 10/01/2023 - Monto: $120.00 - Concepto: Servicios contratados\n",
        "\n",
        "Teléfono: (555) 123-4567\n",
        "\n",
        "Dirección: Calle Ficticia 123, Ciudad Imaginaria, 00000\n",
        "\n",
        "Email: {'.'.join(usuario.lower().split(' '))}@example.com\n",
        "\n",
        "Notas:\n",
        "- Prefiere ser contactado en horario de tarde.\n",
        "- Ha expresado interés en nuevos productos relacionados con software empresarial.\n",
        "\n",
        "Última interacción:\n",
        "Fecha: 15/01/2023\n",
        "Detalle: Se reunió con el representante de ventas para discutir nuevas ofertas.\n",
        "\n",
        "-----------------------------------\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "6Wt30ntQjuKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(clientdb(\"Santiago Hernandez Ramos\"))"
      ],
      "metadata": {
        "id": "vEqjallGknKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Generación de texto con GPT-3.5-turbo Fine-tuned"
      ],
      "metadata": {
        "id": "11hIwH-jJtd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "functions = [\n",
        "        {\n",
        "            \"name\": \"clientdb\",\n",
        "            \"description\": \"Proporciona la informacion de un cliente de la empresa.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"usuario\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"El nombre completo del usuario del que se va a obtener la informacion, ej. Santiago Hernandez Ramos\",\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"usuario\"],\n",
        "            },\n",
        "        }\n",
        "    ]"
      ],
      "metadata": {
        "id": "28-uxdfflBEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def obtener_completion(mensajes, model=\"ft:gpt-3.5-turbo-0613:personal::8CsvktiD\"):\n",
        "  respuesta = openai.ChatCompletion.create(\n",
        "      model=model,\n",
        "      messages=mensajes,\n",
        "      functions=functions, # Proporciono las funciones definidas previamente\n",
        "      temperature=0, # Este hiperparámetro controla la aleatoriedad del modelo\n",
        "  )\n",
        "  return respuesta.choices[0].message # Retornamos el mensaje"
      ],
      "metadata": {
        "id": "AgMlEn-QJzKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ¿Cómo se lo presentamos a los usuarios?"
      ],
      "metadata": {
        "id": "KTtoIOUfN4h6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le presentamos a los usuarios nuestro LLM con fine-tuning a través de una interfaz gráfica en forma de chat."
      ],
      "metadata": {
        "id": "cZZF6agnzph0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def collect_info(_):\n",
        "    prompt = inp.value_input\n",
        "    inp.value = ''\n",
        "    context.append({'role':'user', 'content':f\"{prompt}\"})\n",
        "    response_message = obtener_completion(context)\n",
        "\n",
        "    # Comprobamos si GPT quiere invocar una funcion\n",
        "    if response_message.get(\"function_call\"):\n",
        "        # Invocamos la funcion\n",
        "        available_functions = {\n",
        "            \"clientdb\": clientdb,\n",
        "        }  # Podríamos tener más de una función\n",
        "\n",
        "        # Obtenemos la funcion que quiere invocar GPT\n",
        "        function_name = response_message[\"function_call\"][\"name\"]\n",
        "        function_to_call = available_functions[function_name]\n",
        "        # Obtenemos los argumentos de la funcion proporcionados por GPT\n",
        "        function_args = json.loads(response_message[\"function_call\"][\"arguments\"])\n",
        "        # Invocamos la funcion\n",
        "        function_response = function_to_call(usuario=function_args.get(\"usuario\"))\n",
        "\n",
        "        # Enviamos la respuesta de la función a GPT\n",
        "        context.append(response_message)  # Respuesta del assistant\n",
        "        context.append(\n",
        "            {\n",
        "                \"role\": \"function\",\n",
        "                \"name\": function_name,\n",
        "                \"content\": function_response,\n",
        "            }\n",
        "        )  # Contenido de la función\n",
        "\n",
        "        response_message = obtener_completion(context)\n",
        "\n",
        "    context.append(response_message)\n",
        "    panels.append(\n",
        "        pn.Row('User:', pn.pane.Markdown(prompt, width=600)))\n",
        "    panels.append(\n",
        "        pn.Row('Assistant:', pn.pane.Markdown(response_message['content'], width=600, styles={'background-color': '#F6F6F6'})))\n",
        "    return pn.Column(*panels)"
      ],
      "metadata": {
        "id": "RaRP8YsajjpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def end_chat(event):\n",
        "    panels.append(pn.pane.Alert(\"Chat terminado por el usuario.\", alert_type='success'))\n",
        "    context.append({'role': 'system', 'content':\"Despídete del usuario de manera amable y amigable.\"})\n",
        "    response_message = obtener_completion(context)\n",
        "    context.append(response_message)\n",
        "    panels.append(\n",
        "        pn.Row('Assistant:', pn.pane.Markdown(response_message['content'], width=600, styles={'background-color': '#F6F6F6'})))\n",
        "    return pn.Column(*panels)\n"
      ],
      "metadata": {
        "id": "ZC86THRPjkbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import panel as pn  # GUI\n",
        "pn.extension()\n",
        "\n",
        "panels = []\n",
        "\n",
        "context = [ {'role':'system', 'content':\n",
        "\"\"\"\n",
        "Eres un asistente virtual para gestionar y procesar información de clientes en \\\n",
        "una empresa. Interactúa amablemente con el usuario y solicítale el nombre completo \\\n",
        "de un cliente para comenzar a trabajar.\n",
        "\"\"\"} ]\n",
        "\n",
        "\n",
        "inp = pn.widgets.TextInput(value=\"Hola\", placeholder='Introduce texto aqui...')\n",
        "button_conversation = pn.widgets.Button(name=\"Chat!\")\n",
        "button_end_chat = pn.widgets.Button(name=\"Terminar Chat\")\n",
        "\n",
        "button_end_chat.on_click(end_chat)\n",
        "\n",
        "interactive_conversation = pn.bind(collect_info, button_conversation)\n",
        "\n",
        "dashboard = pn.Column(\n",
        "    inp,\n",
        "    pn.Row(button_conversation, button_end_chat),\n",
        "    pn.panel(interactive_conversation, loading_indicator=True, sizing_mode=\"stretch_both\"),\n",
        ")\n",
        "\n",
        "dashboard"
      ],
      "metadata": {
        "id": "ZJcSukw3jmRM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}